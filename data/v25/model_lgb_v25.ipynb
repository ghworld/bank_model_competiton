{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c284ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.5\n",
      "/d/GH/GitWorkSpace/bank_model_competiton/data/v25\n",
      "-rw-r--r-- 1 chenchen 197121 17048172 Sep  1 16:22 test.dat.v25\n",
      "-rw-r--r-- 1 chenchen 197121 45606251 Sep  1 16:21 train.dat.v25\n",
      "20055 test.dat.v25\n",
      "53481 train.dat.v25\n",
      "train NF 117\n",
      "test NF 116\n",
      "bak\n",
      "model_gbdt_v25.ipynb\n",
      "model_lgb_v25.ipynb\n",
      "model_xgb_v25.ipynb\n",
      "process_v25.ipynb\n",
      "test.dat.v25\n",
      "train.dat.v25\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import os\n",
    "!python --version\n",
    "!pwd\n",
    "suffix=os.path.split(os.getcwd())[-1]\n",
    "!ls -l test.dat.{suffix}\n",
    "!ls -l train.dat.{suffix}\n",
    "!wc -l test.dat.{suffix}\n",
    "!wc -l train.dat.{suffix}\n",
    "!head -n 1 train.dat.v25 | awk -F ',' '{print \"train NF\",NF}'\n",
    "!head -n 1 test.dat.v25  | awk -F ',' '{print \"test NF\",NF}'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5a7909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.dat.v25 test.dat.v25 v25\n",
      "process time :  2025-09-01 16:41:08\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os\n",
    "import time \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "suffix = os.path.split(os.getcwd())[-1]\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "train_dat_path = \"train.dat.%s\" % suffix \n",
    "test_dat_path = \"test.dat.%s\"  % suffix \n",
    "print(train_dat_path, test_dat_path, suffix)\n",
    "print('process time : ',time.strftime( '%Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f699d",
   "metadata": {},
   "source": [
    "# 定义基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "784ee015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_result(pp_ret):\n",
    "    ret = pd.DataFrame({'label' : pp_ret})\n",
    "    df_ret = ret.groupby(pd.cut(pp_ret, bins=20))['label'].agg('count')\n",
    "    df_ret.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f94e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,6))\n",
    "# sns.barplot(x='feat_importances', y='feat', data=df_fea_importance)\n",
    "# plt.set_title('Feature Importance')\n",
    "# plt.xlabel('Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2487d0e5",
   "metadata": {},
   "source": [
    "# KFold 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba57c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id,  title,  career,  zip_code,  residence,  loan,  term,  interest_rate,  issue_time,  \n",
    "# syndicated,  installment,  record_time,  history_time,  total_accounts,  \n",
    "# balance_accounts,  balance_limit,  balance,  level,  label,  cash_has_trans,  \n",
    "# cash_span_months,  cash_total_in_amount,  cash_total_in_count,  cash_total_in_max,  \n",
    "# cash_total_out_amount,  cash_total_out_count,  cash_total_out_max,  \n",
    "# cash_total_net_amount,  cash_month_has_trans_months,  cash_month_neg_amount_months,  \n",
    "# month,  month_in_amount,  month_in_count,  month_in_max,  month_out_amount,  \n",
    "# month_out_count,  month_out_max,  month_net_amount,  cash_month_in_amount_last1m,  \n",
    "# cash_month_out_amount_last1m,  cash_month_net_amount_last1m,  \n",
    "# cash_month_in_amount_last2m,  cash_month_out_amount_last2m,  \n",
    "# cash_month_net_amount_last2m,  cash_month_in_amount_last3m,  \n",
    "# cash_month_out_amount_last3m,  cash_month_net_amount_last3m,  \n",
    "# cash_month_in_amount_last4m,  cash_month_out_amount_last4m,  \n",
    "# cash_month_net_amount_last4m,  cash_month_in_amount_last6m,  \n",
    "# cash_month_out_amount_last6m,  cash_month_net_amount_last6m,  \n",
    "# cash_avg_out_amount,  cash_avg_in_amount,  cash_avg_net_amount,  \n",
    "# cash_aum_month_avg_last_1m,  cash_aum_month_avg_last_2m,  \n",
    "# cash_aum_month_avg_last_3m,  cash_aum_month_avg_last_4m,  \n",
    "# cash_aum_month_avg_last_6m,  loan_total_loan,  loan_month_repay,  \n",
    "# max_txn_time,  loan_has_repayment,  history_time_s,  time_account_day,  \n",
    "# loan_repay_term,  loan_remain_repay_term,  loan_remain_repay_amount,  \n",
    "# loan_total_debt,  loan_balance_ratio,  loan_loan_ratio,  balance_account_avg,  \n",
    "# loan_term_avg,  balance_accounts_ratio,  loan_log,  balance_account_avg_log,  \n",
    "# loan_term_avg_log,  balance_accounts_ratio_log,  interest_rate_log,  \n",
    "# balance_log,  balance_limit_log,  balance_accounts_log,  zip_province,  \n",
    "# zip_city,  level_hash,  level_ord,  grade,  interest_rate_cut,  interest_rate_log_cut,  \n",
    "# balance_cut,  loan_cut,  balance_limit_cut,  loan_term_avg_cut,  \n",
    "# balance_account_avg_cut,  record_time_year,  record_time_month,  \n",
    "# record_time_week,  record_time_year_month,  level_default_ratio,  \n",
    "# interest_rate_default_ratio,  term_default_ratio,  tx_max_min_days,  \n",
    "# tx_count,  total_amount,  1_amount,  0_amount,  total_amount_avg,  1_amount_avg,  \n",
    "# 0_amount_avg,  total_amount_avg2,  1_amount_avg2,  0_amount_avg2,  tx_count_avg,  \n",
    "# tx_tmstp_max,  tx_tmstp_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'id', 'title', 'career', 'zip_code', 'residence', 'loan', 'term',\n",
    "#        'interest_rate', 'issue_time', 'syndicated', 'installment',\n",
    "#        'record_time', 'history_time', 'total_accounts', 'balance_accounts',\n",
    "#        'balance_limit', 'balance', 'level', 'label', 'balance_account_avg',\n",
    "#        'loan_term_avg', 'balance_accounts_ratio', 'loan_log',\n",
    "#        'balance_account_avg_log', 'loan_term_avg_log',\n",
    "#        'balance_accounts_ratio_log', 'interest_rate_log', 'balance_log',\n",
    "#        'balance_limit_log', 'balance_accounts_log', 'zip_province', 'zip_city',\n",
    "#        'level_hash', 'level_ord', 'grade', 'interest_rate_cut',\n",
    "#        'interest_rate_log_cut', 'balance_cut', 'loan_cut', 'balance_limit_cut',\n",
    "#        'loan_term_avg_cut', 'balance_account_avg_cut', 'record_time_year',\n",
    "#        'record_time_month', 'record_time_week', 'record_time_year_month',\n",
    "#        'tx_max_min_days', 'tx_count', 'total_amount', '1_amount', '0_amount',\n",
    "#        'total_amount_avg', '1_amount_avg', '0_amount_avg', 'total_amount_avg2',\n",
    "#        '1_amount_avg2', '0_amount_avg2', 'tx_count_avg', 'tx_tmstp_max',\n",
    "#        'tx_tmstp_min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ada48e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data \n",
      " (53480, 117)\n",
      "test_data  \n",
      " (20054, 116)\n",
      "online arr :  65\n",
      "online arr :  ['id', 'title', 'career', 'zip_code', 'residence', 'loan', 'term', 'interest_rate', 'issue_time', 'syndicated', 'installment', 'record_time', 'history_time', 'total_accounts', 'balance_accounts', 'balance_limit', 'balance', 'level', 'label', 'balance_account_avg', 'loan_term_avg', 'balance_accounts_ratio', 'loan_log', 'balance_account_avg_log', 'loan_term_avg_log', 'balance_accounts_ratio_log', 'interest_rate_log', 'balance_log', 'balance_limit_log', 'balance_accounts_log', 'zip_province', 'zip_city', 'level_hash', 'level_ord', 'grade', 'interest_rate_cut', 'interest_rate_log_cut', 'balance_cut', 'loan_cut', 'balance_limit_cut', 'loan_term_avg_cut', 'balance_account_avg_cut', 'record_time_year', 'record_time_month', 'record_time_week', 'record_time_year_month', 'level_default_ratio', 'interest_rate_default_ratio', 'term_default_ratio', 'tx_max_min_days', 'tx_count', 'total_amount', '1_amount', '0_amount', 'total_amount_avg', '1_amount_avg', '0_amount_avg', 'total_amount_avg2', '1_amount_avg2', '0_amount_avg2', 'tx_count_avg', 'tx_tmstp_max', 'tx_tmstp_min', 'loan_loan_ratio', 'loan_balance_ratio']\n",
      "X_train_train \n",
      " (53480, 72)\n",
      "X_test_test \n",
      " (20054, 72)\n",
      "train_test_data \n",
      " Index(['title', 'career', 'zip_code', 'residence', 'loan', 'term',\n",
      "       'interest_rate', 'issue_time', 'syndicated', 'installment',\n",
      "       'record_time', 'history_time', 'total_accounts', 'balance_accounts',\n",
      "       'balance_limit', 'balance', 'label', 'balance_account_avg',\n",
      "       'loan_term_avg', 'balance_accounts_ratio', 'zip_province', 'zip_city',\n",
      "       'grade', 'record_time_year', 'record_time_month', 'record_time_week',\n",
      "       'record_time_year_month', 'level_default_ratio',\n",
      "       'interest_rate_default_ratio', 'term_default_ratio', 'tx_max_min_days',\n",
      "       'tx_count', 'total_amount', '1_amount', '0_amount', 'total_amount_avg',\n",
      "       '1_amount_avg', '0_amount_avg', 'total_amount_avg2', '1_amount_avg2',\n",
      "       '0_amount_avg2', 'tx_count_avg', 'tx_tmstp_max', 'tx_tmstp_min',\n",
      "       'loan_loan_ratio', 'loan_balance_ratio', 'level_A0', 'level_A1',\n",
      "       'level_A2', 'level_A3', 'level_A4', 'level_A5', 'level_B0', 'level_B1',\n",
      "       'level_B2', 'level_B3', 'level_B4', 'level_B5', 'level_C1', 'level_C2',\n",
      "       'level_C3', 'level_C4', 'level_C5', 'level_D1', 'level_D2', 'level_D3',\n",
      "       'level_D4', 'level_D5', 'level_E1', 'level_E2', 'level_E3', 'level_E4',\n",
      "       'level_E5'],\n",
      "      dtype='object')\n",
      "process time :  2025-09-01 18:07:42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>career</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>residence</th>\n",
       "      <th>loan</th>\n",
       "      <th>term</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>issue_time</th>\n",
       "      <th>syndicated</th>\n",
       "      <th>installment</th>\n",
       "      <th>record_time</th>\n",
       "      <th>history_time</th>\n",
       "      <th>total_accounts</th>\n",
       "      <th>balance_accounts</th>\n",
       "      <th>balance_limit</th>\n",
       "      <th>balance</th>\n",
       "      <th>label</th>\n",
       "      <th>balance_account_avg</th>\n",
       "      <th>loan_term_avg</th>\n",
       "      <th>balance_accounts_ratio</th>\n",
       "      <th>zip_province</th>\n",
       "      <th>zip_city</th>\n",
       "      <th>grade</th>\n",
       "      <th>record_time_year</th>\n",
       "      <th>record_time_month</th>\n",
       "      <th>record_time_week</th>\n",
       "      <th>record_time_year_month</th>\n",
       "      <th>level_default_ratio</th>\n",
       "      <th>interest_rate_default_ratio</th>\n",
       "      <th>term_default_ratio</th>\n",
       "      <th>tx_max_min_days</th>\n",
       "      <th>tx_count</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>1_amount</th>\n",
       "      <th>0_amount</th>\n",
       "      <th>total_amount_avg</th>\n",
       "      <th>1_amount_avg</th>\n",
       "      <th>0_amount_avg</th>\n",
       "      <th>total_amount_avg2</th>\n",
       "      <th>1_amount_avg2</th>\n",
       "      <th>0_amount_avg2</th>\n",
       "      <th>tx_count_avg</th>\n",
       "      <th>tx_tmstp_max</th>\n",
       "      <th>tx_tmstp_min</th>\n",
       "      <th>loan_loan_ratio</th>\n",
       "      <th>loan_balance_ratio</th>\n",
       "      <th>level_A0</th>\n",
       "      <th>level_A1</th>\n",
       "      <th>level_A2</th>\n",
       "      <th>level_A3</th>\n",
       "      <th>level_A4</th>\n",
       "      <th>level_A5</th>\n",
       "      <th>level_B0</th>\n",
       "      <th>level_B1</th>\n",
       "      <th>level_B2</th>\n",
       "      <th>level_B3</th>\n",
       "      <th>level_B4</th>\n",
       "      <th>level_B5</th>\n",
       "      <th>level_C1</th>\n",
       "      <th>level_C2</th>\n",
       "      <th>level_C3</th>\n",
       "      <th>level_C4</th>\n",
       "      <th>level_C5</th>\n",
       "      <th>level_D1</th>\n",
       "      <th>level_D2</th>\n",
       "      <th>level_D3</th>\n",
       "      <th>level_D4</th>\n",
       "      <th>level_D5</th>\n",
       "      <th>level_E1</th>\n",
       "      <th>level_E2</th>\n",
       "      <th>level_E3</th>\n",
       "      <th>level_E4</th>\n",
       "      <th>level_E5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221373</td>\n",
       "      <td>1</td>\n",
       "      <td>7200</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>1238631967</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1238630622</td>\n",
       "      <td>472006661</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36200.0</td>\n",
       "      <td>13856.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1539.555556</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>22</td>\n",
       "      <td>2213</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>200904</td>\n",
       "      <td>0.167864</td>\n",
       "      <td>0.166035</td>\n",
       "      <td>0.148731</td>\n",
       "      <td>163.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>71787.0</td>\n",
       "      <td>12079.50</td>\n",
       "      <td>59707.50</td>\n",
       "      <td>440.411043</td>\n",
       "      <td>74.107362</td>\n",
       "      <td>366.303681</td>\n",
       "      <td>1495.562500</td>\n",
       "      <td>251.656250</td>\n",
       "      <td>1243.906250</td>\n",
       "      <td>0.294479</td>\n",
       "      <td>1.238198e+09</td>\n",
       "      <td>1.224115e+09</td>\n",
       "      <td>0.198895</td>\n",
       "      <td>0.382762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>311681</td>\n",
       "      <td>0</td>\n",
       "      <td>21300</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1295</td>\n",
       "      <td>1128212052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1161907665</td>\n",
       "      <td>763779041</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20400.0</td>\n",
       "      <td>13773.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1530.333333</td>\n",
       "      <td>591.666667</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>31</td>\n",
       "      <td>3116</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>200610</td>\n",
       "      <td>0.183134</td>\n",
       "      <td>0.184066</td>\n",
       "      <td>0.148731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.044118</td>\n",
       "      <td>0.675147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>271562</td>\n",
       "      <td>1</td>\n",
       "      <td>10400</td>\n",
       "      <td>60</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>1249171509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1383958593</td>\n",
       "      <td>727143443</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>2023.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.777778</td>\n",
       "      <td>173.333333</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>27</td>\n",
       "      <td>2715</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>201311</td>\n",
       "      <td>0.238525</td>\n",
       "      <td>0.241333</td>\n",
       "      <td>0.316692</td>\n",
       "      <td>180.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>22406.1</td>\n",
       "      <td>15883.72</td>\n",
       "      <td>6522.38</td>\n",
       "      <td>124.478333</td>\n",
       "      <td>88.242889</td>\n",
       "      <td>36.235444</td>\n",
       "      <td>466.793750</td>\n",
       "      <td>330.910833</td>\n",
       "      <td>135.882917</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.383955e+09</td>\n",
       "      <td>1.368403e+09</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.187315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>522083</td>\n",
       "      <td>0</td>\n",
       "      <td>33050</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>1172882234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1214353935</td>\n",
       "      <td>687660346</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>21992.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2443.555556</td>\n",
       "      <td>918.055556</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>52</td>\n",
       "      <td>5220</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>200806</td>\n",
       "      <td>0.233343</td>\n",
       "      <td>0.229479</td>\n",
       "      <td>0.148731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.338057</td>\n",
       "      <td>0.890364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>101026</td>\n",
       "      <td>1</td>\n",
       "      <td>5200</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>1172882384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1240274527</td>\n",
       "      <td>322012875</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>1669.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185.444444</td>\n",
       "      <td>144.444444</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>10</td>\n",
       "      <td>1010</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>200904</td>\n",
       "      <td>0.215479</td>\n",
       "      <td>0.221494</td>\n",
       "      <td>0.148731</td>\n",
       "      <td>169.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>51163.0</td>\n",
       "      <td>30823.10</td>\n",
       "      <td>20339.90</td>\n",
       "      <td>302.739645</td>\n",
       "      <td>182.385207</td>\n",
       "      <td>120.354438</td>\n",
       "      <td>550.139785</td>\n",
       "      <td>331.431183</td>\n",
       "      <td>218.708602</td>\n",
       "      <td>0.550296</td>\n",
       "      <td>1.238285e+09</td>\n",
       "      <td>1.223683e+09</td>\n",
       "      <td>1.019608</td>\n",
       "      <td>0.327255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73529</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>601107</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>1130976000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1125964800</td>\n",
       "      <td>1018224000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3818.0</td>\n",
       "      <td>2224.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>741.563333</td>\n",
       "      <td>833.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>60</td>\n",
       "      <td>6011</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>200509</td>\n",
       "      <td>0.167864</td>\n",
       "      <td>0.274146</td>\n",
       "      <td>0.182842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.619172</td>\n",
       "      <td>0.582685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73530</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>601102</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>1156204800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1157068800</td>\n",
       "      <td>1054425600</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5502.0</td>\n",
       "      <td>4126.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>687.785000</td>\n",
       "      <td>833.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>6011</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>200609</td>\n",
       "      <td>0.238525</td>\n",
       "      <td>0.190647</td>\n",
       "      <td>0.182842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.817521</td>\n",
       "      <td>0.750038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73531</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>601408</td>\n",
       "      <td>1</td>\n",
       "      <td>11000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>1144108800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1111622400</td>\n",
       "      <td>1037404800</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4844.0</td>\n",
       "      <td>2710.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>903.653333</td>\n",
       "      <td>916.666667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>60</td>\n",
       "      <td>6014</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>200503</td>\n",
       "      <td>0.149012</td>\n",
       "      <td>0.218543</td>\n",
       "      <td>0.182842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.270851</td>\n",
       "      <td>0.559653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73532</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>601904</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>1163808000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1116892800</td>\n",
       "      <td>1057017600</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3495.0</td>\n",
       "      <td>1834.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>611.643333</td>\n",
       "      <td>666.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>60</td>\n",
       "      <td>6019</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>200505</td>\n",
       "      <td>0.149012</td>\n",
       "      <td>0.219020</td>\n",
       "      <td>0.182842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.288984</td>\n",
       "      <td>0.525016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73533</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>601809</td>\n",
       "      <td>1</td>\n",
       "      <td>7000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>1188777600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1146614400</td>\n",
       "      <td>1047600000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>662.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>662.560000</td>\n",
       "      <td>583.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>60</td>\n",
       "      <td>6018</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>200605</td>\n",
       "      <td>0.215479</td>\n",
       "      <td>0.225832</td>\n",
       "      <td>0.182842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.462687</td>\n",
       "      <td>0.706354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73534 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       title  career  zip_code  residence   loan  term  interest_rate  \\\n",
       "0          9     0.0    221373          1   7200    36         0.1095   \n",
       "1          8    10.0    311681          0  21300    36         0.1295   \n",
       "2          8     7.0    271562          1  10400    60         0.2105   \n",
       "3          7     2.0    522083          0  33050    36         0.1640   \n",
       "4          8     3.0    101026          1   5200    36         0.1435   \n",
       "...      ...     ...       ...        ...    ...   ...            ...   \n",
       "73529      0     8.0    601107          1  10000    12         0.1885   \n",
       "73530      0    10.0    601102          1  10000    12         0.2930   \n",
       "73531      0     4.0    601408          1  11000    12         0.2475   \n",
       "73532      0     3.0    601904          1   8000    12         0.2200   \n",
       "73533      2     1.0    601809          1   7000    12         0.1495   \n",
       "\n",
       "       issue_time  syndicated  installment  record_time  history_time  \\\n",
       "0      1238631967           0            1   1238630622     472006661   \n",
       "1      1128212052           0            0   1161907665     763779041   \n",
       "2      1249171509           0            0   1383958593     727143443   \n",
       "3      1172882234           0            1   1214353935     687660346   \n",
       "4      1172882384           0            0   1240274527     322012875   \n",
       "...           ...         ...          ...          ...           ...   \n",
       "73529  1130976000           0            0   1125964800    1018224000   \n",
       "73530  1156204800           0            0   1157068800    1054425600   \n",
       "73531  1144108800           0            0   1111622400    1037404800   \n",
       "73532  1163808000           0            0   1116892800    1057017600   \n",
       "73533  1188777600           0            0   1146614400    1047600000   \n",
       "\n",
       "       total_accounts  balance_accounts  balance_limit   balance  label  \\\n",
       "0                17.0               9.0        36200.0  13856.00    0.0   \n",
       "1                17.0               9.0        20400.0  13773.00    1.0   \n",
       "2                17.0               9.0        10800.0   2023.00    0.0   \n",
       "3                17.0               9.0        24700.0  21992.00    0.0   \n",
       "4                17.0               9.0         5100.0   1669.00    1.0   \n",
       "...               ...               ...            ...       ...    ...   \n",
       "73529             6.0               3.0         3818.0   2224.69    0.0   \n",
       "73530             6.0               6.0         5502.0   4126.71    0.0   \n",
       "73531             8.0               3.0         4844.0   2710.96    0.0   \n",
       "73532             6.0               3.0         3495.0   1834.93    0.0   \n",
       "73533             2.0               1.0          938.0    662.56    0.0   \n",
       "\n",
       "       balance_account_avg  loan_term_avg  balance_accounts_ratio  \\\n",
       "0              1539.555556     200.000000                0.529412   \n",
       "1              1530.333333     591.666667                0.529412   \n",
       "2               224.777778     173.333333                0.529412   \n",
       "3              2443.555556     918.055556                0.529412   \n",
       "4               185.444444     144.444444                0.529412   \n",
       "...                    ...            ...                     ...   \n",
       "73529           741.563333     833.333333                0.500000   \n",
       "73530           687.785000     833.333333                1.000000   \n",
       "73531           903.653333     916.666667                0.375000   \n",
       "73532           611.643333     666.666667                0.500000   \n",
       "73533           662.560000     583.333333                0.500000   \n",
       "\n",
       "       zip_province  zip_city  grade  record_time_year  record_time_month  \\\n",
       "0                22      2213      1              2009                  4   \n",
       "1                31      3116      2              2006                 10   \n",
       "2                27      2715      2              2013                 11   \n",
       "3                52      5220      2              2008                  6   \n",
       "4                10      1010      2              2009                  4   \n",
       "...             ...       ...    ...               ...                ...   \n",
       "73529            60      6011      1              2005                  9   \n",
       "73530            60      6011      2              2006                  9   \n",
       "73531            60      6014      1              2005                  3   \n",
       "73532            60      6019      1              2005                  5   \n",
       "73533            60      6018      2              2006                  5   \n",
       "\n",
       "       record_time_week  record_time_year_month  level_default_ratio  \\\n",
       "0                    14                  200904             0.167864   \n",
       "1                    43                  200610             0.183134   \n",
       "2                    45                  201311             0.238525   \n",
       "3                    26                  200806             0.233343   \n",
       "4                    17                  200904             0.215479   \n",
       "...                 ...                     ...                  ...   \n",
       "73529                36                  200509             0.167864   \n",
       "73530                35                  200609             0.238525   \n",
       "73531                12                  200503             0.149012   \n",
       "73532                21                  200505             0.149012   \n",
       "73533                18                  200605             0.215479   \n",
       "\n",
       "       interest_rate_default_ratio  term_default_ratio  tx_max_min_days  \\\n",
       "0                         0.166035            0.148731            163.0   \n",
       "1                         0.184066            0.148731              0.0   \n",
       "2                         0.241333            0.316692            180.0   \n",
       "3                         0.229479            0.148731              0.0   \n",
       "4                         0.221494            0.148731            169.0   \n",
       "...                            ...                 ...              ...   \n",
       "73529                     0.274146            0.182842              0.0   \n",
       "73530                     0.190647            0.182842              0.0   \n",
       "73531                     0.218543            0.182842              0.0   \n",
       "73532                     0.219020            0.182842              0.0   \n",
       "73533                     0.225832            0.182842              0.0   \n",
       "\n",
       "       tx_count  total_amount  1_amount  0_amount  total_amount_avg  \\\n",
       "0          48.0       71787.0  12079.50  59707.50        440.411043   \n",
       "1           0.0           0.0      0.00      0.00          0.000000   \n",
       "2          48.0       22406.1  15883.72   6522.38        124.478333   \n",
       "3           0.0           0.0      0.00      0.00          0.000000   \n",
       "4          93.0       51163.0  30823.10  20339.90        302.739645   \n",
       "...         ...           ...       ...       ...               ...   \n",
       "73529       0.0           0.0      0.00      0.00          0.000000   \n",
       "73530       0.0           0.0      0.00      0.00          0.000000   \n",
       "73531       0.0           0.0      0.00      0.00          0.000000   \n",
       "73532       0.0           0.0      0.00      0.00          0.000000   \n",
       "73533       0.0           0.0      0.00      0.00          0.000000   \n",
       "\n",
       "       1_amount_avg  0_amount_avg  total_amount_avg2  1_amount_avg2  \\\n",
       "0         74.107362    366.303681        1495.562500     251.656250   \n",
       "1          0.000000      0.000000           0.000000       0.000000   \n",
       "2         88.242889     36.235444         466.793750     330.910833   \n",
       "3          0.000000      0.000000           0.000000       0.000000   \n",
       "4        182.385207    120.354438         550.139785     331.431183   \n",
       "...             ...           ...                ...            ...   \n",
       "73529      0.000000      0.000000           0.000000       0.000000   \n",
       "73530      0.000000      0.000000           0.000000       0.000000   \n",
       "73531      0.000000      0.000000           0.000000       0.000000   \n",
       "73532      0.000000      0.000000           0.000000       0.000000   \n",
       "73533      0.000000      0.000000           0.000000       0.000000   \n",
       "\n",
       "       0_amount_avg2  tx_count_avg  tx_tmstp_max  tx_tmstp_min  \\\n",
       "0        1243.906250      0.294479  1.238198e+09  1.224115e+09   \n",
       "1           0.000000      0.000000  0.000000e+00  0.000000e+00   \n",
       "2         135.882917      0.266667  1.383955e+09  1.368403e+09   \n",
       "3           0.000000      0.000000  0.000000e+00  0.000000e+00   \n",
       "4         218.708602      0.550296  1.238285e+09  1.223683e+09   \n",
       "...              ...           ...           ...           ...   \n",
       "73529       0.000000      0.000000  0.000000e+00  0.000000e+00   \n",
       "73530       0.000000      0.000000  0.000000e+00  0.000000e+00   \n",
       "73531       0.000000      0.000000  0.000000e+00  0.000000e+00   \n",
       "73532       0.000000      0.000000  0.000000e+00  0.000000e+00   \n",
       "73533       0.000000      0.000000  0.000000e+00  0.000000e+00   \n",
       "\n",
       "       loan_loan_ratio  loan_balance_ratio  level_A0  level_A1  level_A2  \\\n",
       "0             0.198895            0.382762         0         0         0   \n",
       "1             1.044118            0.675147         0         0         0   \n",
       "2             0.962963            0.187315         0         0         0   \n",
       "3             1.338057            0.890364         0         0         0   \n",
       "4             1.019608            0.327255         0         0         0   \n",
       "...                ...                 ...       ...       ...       ...   \n",
       "73529         2.619172            0.582685         0         0         0   \n",
       "73530         1.817521            0.750038         0         0         0   \n",
       "73531         2.270851            0.559653         0         0         0   \n",
       "73532         2.288984            0.525016         0         0         0   \n",
       "73533         7.462687            0.706354         0         0         0   \n",
       "\n",
       "       level_A3  level_A4  level_A5  level_B0  level_B1  level_B2  level_B3  \\\n",
       "0             0         1         0         0         0         0         0   \n",
       "1             0         0         0         1         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         1   \n",
       "4             0         0         0         0         0         1         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "73529         0         1         0         0         0         0         0   \n",
       "73530         0         0         0         0         0         0         0   \n",
       "73531         1         0         0         0         0         0         0   \n",
       "73532         1         0         0         0         0         0         0   \n",
       "73533         0         0         0         0         0         1         0   \n",
       "\n",
       "       level_B4  level_B5  level_C1  level_C2  level_C3  level_C4  level_C5  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             1         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "73529         0         0         0         0         0         0         0   \n",
       "73530         1         0         0         0         0         0         0   \n",
       "73531         0         0         0         0         0         0         0   \n",
       "73532         0         0         0         0         0         0         0   \n",
       "73533         0         0         0         0         0         0         0   \n",
       "\n",
       "       level_D1  level_D2  level_D3  level_D4  level_D5  level_E1  level_E2  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "73529         0         0         0         0         0         0         0   \n",
       "73530         0         0         0         0         0         0         0   \n",
       "73531         0         0         0         0         0         0         0   \n",
       "73532         0         0         0         0         0         0         0   \n",
       "73533         0         0         0         0         0         0         0   \n",
       "\n",
       "       level_E3  level_E4  level_E5  \n",
       "0             0         0         0  \n",
       "1             0         0         0  \n",
       "2             0         0         0  \n",
       "3             0         0         0  \n",
       "4             0         0         0  \n",
       "...         ...       ...       ...  \n",
       "73529         0         0         0  \n",
       "73530         0         0         0  \n",
       "73531         0         0         0  \n",
       "73532         0         0         0  \n",
       "73533         0         0         0  \n",
       "\n",
       "[73534 rows x 73 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_fea=['id', 'level']\n",
    "\n",
    "col_v1_str ='id,title,career,zip_code,residence,loan,term,interest_rate,issue_time,syndicated,installment,record_time,history_time,total_accounts,balance_accounts,balance_limit,balance,level,label,balance_account_avg,loan_term_avg,balance_accounts_ratio,loan_log,balance_account_avg_log,loan_term_avg_log,balance_accounts_ratio_log,interest_rate_log,balance_log,balance_limit_log,balance_accounts_log,zip_province,zip_city,level_hash,level_ord,grade,interest_rate_cut,interest_rate_log_cut,balance_cut,loan_cut,balance_limit_cut,loan_term_avg_cut,balance_account_avg_cut,record_time_year,record_time_month,record_time_week,record_time_year_month,level_default_ratio,interest_rate_default_ratio,term_default_ratio,tx_max_min_days,tx_count,total_amount,1_amount,0_amount,total_amount_avg,1_amount_avg,0_amount_avg,total_amount_avg2,1_amount_avg2,0_amount_avg2,tx_count_avg,tx_tmstp_max,tx_tmstp_min'\n",
    "keep_arr = col_v1_str.split(',')\n",
    "col_v2_arr = ['loan_loan_ratio', 'loan_balance_ratio']\n",
    "keep_arr.extend(col_v2_arr)\n",
    "\n",
    "# 去掉\n",
    "# level hash in drop fea  \n",
    "drop_fea = ['tx_time_max', 'tx_time_min', 'level_hash', 'level_ord','loan_log',\n",
    "       'balance_account_avg_log', 'loan_term_avg_log',\n",
    "       'balance_accounts_ratio_log', 'interest_rate_log', 'balance_log',\n",
    "       'balance_limit_log', 'balance_accounts_log', 'interest_rate_cut',\n",
    "       'interest_rate_log_cut', 'balance_cut', 'loan_cut', 'balance_limit_cut',\n",
    "       'loan_term_avg_cut', 'balance_account_avg_cut',\n",
    "       'level_deafault_ratio', 'interest_rate_deafault_ratio','term_deafault_ratio'\n",
    "       ]\n",
    "\n",
    "train_data = pd.read_csv(train_dat_path, engine = 'python');\n",
    "test_data  = pd.read_csv(test_dat_path,  engine = 'python');\n",
    "print('train_data \\n', train_data.shape)\n",
    "print('test_data  \\n', test_data.shape)\n",
    "\n",
    "#只保留有效特征\n",
    "online_arr = []\n",
    "for col_name in  keep_arr :\n",
    "    if col_name in train_data.columns :\n",
    "        online_arr.append(col_name)\n",
    "print('online arr : ', len(online_arr))\n",
    "print('online arr : ', online_arr)\n",
    "        \n",
    "train_test_data = pd.concat([train_data, test_data], axis=0, ignore_index = True)\n",
    "train_test_data = train_test_data.loc[:,online_arr]\n",
    "\n",
    "for col_name in drop_fea : \n",
    "    if col_name in train_test_data.columns:\n",
    "        train_test_data.drop([col_name], axis=1, inplace=True)\n",
    "train_test_data = train_test_data.fillna(0)\n",
    "train_test_data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "dummy_df = pd.get_dummies(train_test_data.loc[:,dummy_fea])\n",
    "train_test_data = pd.concat([train_test_data, dummy_df], axis=1)\n",
    "train_test_data = train_test_data.drop(dummy_fea, axis=1)\n",
    "\n",
    "\n",
    "train_train = train_test_data.iloc[:train_data.shape[0],:]\n",
    "test_test   = train_test_data.iloc[train_data.shape[0]:,:]\n",
    "\n",
    "y_train_train = train_train['label'].values\n",
    "X_train_train = train_train.drop(['label'], axis=1)\n",
    "y_test_test  = test_test['label'].values\n",
    "X_test_test  = test_test.drop(['label'], axis=1)\n",
    "print('X_train_train \\n', X_train_train.shape)\n",
    "print('X_test_test \\n', X_test_test.shape)\n",
    "print('train_test_data \\n', train_test_data.columns)\n",
    "print('process time : ',time.strftime( '%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "train_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec53b9",
   "metadata": {},
   "source": [
    "# LGB model1 SKfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea5e1dfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train \n",
      " [    0     2     3 ... 53477 53478 53479]\n",
      "test  \n",
      " [    1    17    41 ... 53437 53442 53460]\n",
      "[200]\ttraining's auc: 0.695954\tvalid_1's auc: 0.662684\n",
      "[400]\ttraining's auc: 0.725067\tvalid_1's auc: 0.665183\n",
      "[600]\ttraining's auc: 0.749434\tvalid_1's auc: 0.665586\n",
      "[800]\ttraining's auc: 0.772536\tvalid_1's auc: 0.666671\n",
      "[1000]\ttraining's auc: 0.793087\tvalid_1's auc: 0.665929\n",
      "final pred \n",
      " [0.09753534 0.0458687  0.13285965 ... 0.19859582 0.19330057 0.20239045]\n",
      "--------------the 0 epoch lgb_model valid auc -------------  0.7930873215169455 0.6659294562270178\n",
      "train \n",
      " [    0     1     2 ... 53477 53478 53479]\n",
      "test  \n",
      " [    3    20    24 ... 53441 53447 53458]\n",
      "[200]\ttraining's auc: 0.697406\tvalid_1's auc: 0.659148\n",
      "[400]\ttraining's auc: 0.724698\tvalid_1's auc: 0.658293\n",
      "[600]\ttraining's auc: 0.750106\tvalid_1's auc: 0.661088\n",
      "[800]\ttraining's auc: 0.772426\tvalid_1's auc: 0.660766\n",
      "[1000]\ttraining's auc: 0.792071\tvalid_1's auc: 0.662338\n",
      "final pred \n",
      " [0.11365545 0.04698794 0.13528261 ... 0.20139606 0.18424879 0.20029061]\n",
      "--------------the 1 epoch lgb_model valid auc -------------  0.7920706525972836 0.6623384281097946\n",
      "train \n",
      " [    0     1     2 ... 53477 53478 53479]\n",
      "test  \n",
      " [    4     7     8 ... 53467 53473 53474]\n",
      "[200]\ttraining's auc: 0.695842\tvalid_1's auc: 0.671815\n",
      "[400]\ttraining's auc: 0.72383\tvalid_1's auc: 0.671176\n",
      "[600]\ttraining's auc: 0.748885\tvalid_1's auc: 0.672865\n",
      "[800]\ttraining's auc: 0.773127\tvalid_1's auc: 0.672822\n",
      "[1000]\ttraining's auc: 0.793701\tvalid_1's auc: 0.673521\n",
      "final pred \n",
      " [0.11325354 0.04924263 0.14771679 ... 0.19709283 0.1786431  0.20022477]\n",
      "--------------the 2 epoch lgb_model valid auc -------------  0.7937007118807321 0.6735213756459852\n",
      "train \n",
      " [    0     1     2 ... 53477 53478 53479]\n",
      "test  \n",
      " [    5    10    14 ... 53452 53453 53469]\n",
      "[200]\ttraining's auc: 0.696247\tvalid_1's auc: 0.663107\n",
      "[400]\ttraining's auc: 0.724366\tvalid_1's auc: 0.664364\n",
      "[600]\ttraining's auc: 0.751643\tvalid_1's auc: 0.665243\n",
      "[800]\ttraining's auc: 0.774382\tvalid_1's auc: 0.667206\n",
      "[1000]\ttraining's auc: 0.796272\tvalid_1's auc: 0.670246\n",
      "final pred \n",
      " [0.11752425 0.05021078 0.11862047 ... 0.20585136 0.18564504 0.21751206]\n",
      "--------------the 3 epoch lgb_model valid auc -------------  0.7962720277628733 0.6702460722454918\n",
      "train \n",
      " [    0     1     2 ... 53476 53477 53478]\n",
      "test  \n",
      " [    9    12    15 ... 53431 53471 53479]\n",
      "[200]\ttraining's auc: 0.697804\tvalid_1's auc: 0.667007\n",
      "[400]\ttraining's auc: 0.725701\tvalid_1's auc: 0.669007\n",
      "[600]\ttraining's auc: 0.753177\tvalid_1's auc: 0.66591\n",
      "[800]\ttraining's auc: 0.775962\tvalid_1's auc: 0.665129\n",
      "[1000]\ttraining's auc: 0.797132\tvalid_1's auc: 0.66615\n",
      "final pred \n",
      " [0.10682588 0.0459407  0.14490047 ... 0.20489238 0.18223663 0.20626407]\n",
      "--------------the 4 epoch lgb_model valid auc -------------  0.7971318340219902 0.6661496233749032\n",
      "train \n",
      " [    0     1     2 ... 53477 53478 53479]\n",
      "test  \n",
      " [   21    32    37 ... 53445 53454 53455]\n",
      "[200]\ttraining's auc: 0.696998\tvalid_1's auc: 0.65007\n",
      "[400]\ttraining's auc: 0.724847\tvalid_1's auc: 0.654078\n",
      "[600]\ttraining's auc: 0.752955\tvalid_1's auc: 0.656438\n",
      "[800]\ttraining's auc: 0.775612\tvalid_1's auc: 0.655532\n",
      "[1000]\ttraining's auc: 0.795544\tvalid_1's auc: 0.655993\n",
      "final pred \n",
      " [0.10710749 0.04785783 0.0978874  ... 0.19419534 0.17725927 0.20379791]\n",
      "--------------the 5 epoch lgb_model valid auc -------------  0.7955444914580719 0.6559931673274104\n",
      "train \n",
      " [    0     1     2 ... 53475 53478 53479]\n",
      "test  \n",
      " [   11    19    27 ... 53463 53476 53477]\n",
      "[200]\ttraining's auc: 0.696187\tvalid_1's auc: 0.652333\n",
      "[400]\ttraining's auc: 0.724244\tvalid_1's auc: 0.655616\n",
      "[600]\ttraining's auc: 0.753199\tvalid_1's auc: 0.657019\n",
      "[800]\ttraining's auc: 0.779094\tvalid_1's auc: 0.657362\n",
      "[1000]\ttraining's auc: 0.799333\tvalid_1's auc: 0.655904\n",
      "final pred \n",
      " [0.11692061 0.04864011 0.15975966 ... 0.19778871 0.1881913  0.19110871]\n",
      "--------------the 6 epoch lgb_model valid auc -------------  0.7993327138337218 0.6559040939204848\n",
      "train \n",
      " [    0     1     3 ... 53477 53478 53479]\n",
      "test  \n",
      " [    2    34    35 ... 53456 53457 53464]\n",
      "[200]\ttraining's auc: 0.696576\tvalid_1's auc: 0.660294\n",
      "[400]\ttraining's auc: 0.725831\tvalid_1's auc: 0.667741\n",
      "[600]\ttraining's auc: 0.75128\tvalid_1's auc: 0.670266\n",
      "[800]\ttraining's auc: 0.774988\tvalid_1's auc: 0.670385\n",
      "[1000]\ttraining's auc: 0.795004\tvalid_1's auc: 0.670228\n",
      "final pred \n",
      " [0.12579809 0.04867764 0.15289602 ... 0.18767575 0.18692745 0.21734907]\n",
      "--------------the 7 epoch lgb_model valid auc -------------  0.7950037427842953 0.6702279792097101\n",
      "train \n",
      " [    1     2     3 ... 53477 53478 53479]\n",
      "test  \n",
      " [    0    18    25 ... 53461 53465 53472]\n",
      "[200]\ttraining's auc: 0.697692\tvalid_1's auc: 0.646176\n",
      "[400]\ttraining's auc: 0.72508\tvalid_1's auc: 0.651738\n",
      "[600]\ttraining's auc: 0.750555\tvalid_1's auc: 0.654281\n",
      "[800]\ttraining's auc: 0.772957\tvalid_1's auc: 0.656019\n",
      "[1000]\ttraining's auc: 0.793311\tvalid_1's auc: 0.655616\n",
      "final pred \n",
      " [0.10686221 0.04870176 0.14255468 ... 0.19178709 0.19097709 0.21771667]\n",
      "--------------the 8 epoch lgb_model valid auc -------------  0.793310512651276 0.6556164610439542\n",
      "train \n",
      " [    0     1     2 ... 53476 53477 53479]\n",
      "test  \n",
      " [    6    26    59 ... 53470 53475 53478]\n",
      "[200]\ttraining's auc: 0.695574\tvalid_1's auc: 0.656135\n",
      "[400]\ttraining's auc: 0.726157\tvalid_1's auc: 0.658516\n",
      "[600]\ttraining's auc: 0.7527\tvalid_1's auc: 0.660958\n",
      "[800]\ttraining's auc: 0.777329\tvalid_1's auc: 0.663348\n",
      "[1000]\ttraining's auc: 0.798369\tvalid_1's auc: 0.663056\n",
      "final pred \n",
      " [0.09819278 0.04023497 0.12674043 ... 0.20300672 0.17893379 0.20881877]\n",
      "--------------the 9 epoch lgb_model valid auc -------------  0.7983693944488156 0.6630559462182193\n",
      "auc arr \n",
      "           0         1\n",
      "0  0.793087  0.665929\n",
      "1  0.792071  0.662338\n",
      "2  0.793701  0.673521\n",
      "3  0.796272  0.670246\n",
      "4  0.797132  0.666150\n",
      "5  0.795544  0.655993\n",
      "6  0.799333  0.655904\n",
      "7  0.795004  0.670228\n",
      "8  0.793311  0.655616\n",
      "9  0.798369  0.663056\n",
      "auc arr describe \n",
      "                0          1\n",
      "count  10.000000  10.000000\n",
      "mean    0.795382   0.663898\n",
      "std     0.002401   0.006500\n",
      "min     0.792071   0.655616\n",
      "25%     0.793408   0.657579\n",
      "50%     0.795274   0.664493\n",
      "75%     0.796917   0.669208\n",
      "max     0.799333   0.673521\n",
      "process time :  2025-09-01 18:09:18\n"
     ]
    }
   ],
   "source": [
    "def lgb_feature(X_train, y_train, X_test, y_test, category_feature= []):\n",
    "    lgb_train = lgb.Dataset(X_train, y_train,categorical_feature = category_feature)\n",
    "    lgb_test = lgb.Dataset(X_test,   y_test, categorical_feature = category_feature)\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric':'auc',\n",
    "        'num_leaves': 25,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'min_data_in_leaf':5,\n",
    "        'max_bin':200,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "    watchlist = [lgb_train , lgb_test]\n",
    "    gbm = lgb.train(params,lgb_train,\n",
    "                    valid_sets = [lgb_train , lgb_test], \n",
    "                    num_boost_round=1000,\n",
    "                   callbacks = [log_evaluation(period=200)])\n",
    "    predict = gbm.predict(X_test)\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return gbm, vfunc(predict)\n",
    "\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "n_folds = 10\n",
    "answers = []\n",
    "models  = []\n",
    "auc_arr = [] \n",
    "\n",
    "cate_feature = []\n",
    "\n",
    "SEED = 10\n",
    "sk = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "smote = SMOTE(random_state=SEED)\n",
    "y_train_train = pd.DataFrame(y_train_train)\n",
    "for i,(train,test) in enumerate(sk.split(X_train_train, y_train_train)):\n",
    "    print('train \\n', train)\n",
    "    print('test  \\n', test)\n",
    "    X_train = X_train_train.iloc[train]\n",
    "    y_train = y_train_train.iloc[train]\n",
    "    X_test  = X_train_train.iloc[test]\n",
    "    y_test  = y_train_train.iloc[test]\n",
    "#     X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "#     print('after smote :', X_train.shape, y_train.shape， len(list(map(lambda x : x==1,y_train))) )\n",
    "    lgb_clf, test_pred = lgb_feature(X_train, y_train, X_test, y_test)\n",
    "    models.append(lgb_clf)\n",
    "    train_pred = lgb_clf.predict(X_train)\n",
    "    # 记录训练集auc, 测试集auc\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc  = roc_auc_score(y_test, test_pred)\n",
    "    auc_arr.append((train_auc,test_auc))\n",
    "    #最终输出\n",
    "    final_pred = lgb_clf.predict(X_test_test)\n",
    "    print('final pred \\n', final_pred)\n",
    "    answers.append(final_pred)\n",
    "    print('--------------the %d epoch lgb_model valid auc ------------- ' % i, train_auc, test_auc)\n",
    "print('auc arr \\n', pd.DataFrame(auc_arr))\n",
    "print('auc arr describe \\n', pd.DataFrame(auc_arr).describe())\n",
    "\n",
    "# print('# --------------------------- retrain ------------------------------------ #')\n",
    "# lgb_lgb_clf, test_test_pred = lgb_feature(X_train_train, y_train_train, X_test_test, y_test_test)\n",
    "print('process time : ',time.strftime( '%Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b4ed7",
   "metadata": {},
   "source": [
    "# 特征重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29f6df82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>issue_time</td>\n",
       "      <td>1360</td>\n",
       "      <td>14490.952175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interest_rate</td>\n",
       "      <td>1322</td>\n",
       "      <td>23407.413197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>history_time</td>\n",
       "      <td>1132</td>\n",
       "      <td>10093.139229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>loan_balance_ratio</td>\n",
       "      <td>977</td>\n",
       "      <td>8591.403071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>balance_account_avg</td>\n",
       "      <td>938</td>\n",
       "      <td>8452.008111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>balance_accounts_ratio</td>\n",
       "      <td>934</td>\n",
       "      <td>8927.602976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>loan_loan_ratio</td>\n",
       "      <td>924</td>\n",
       "      <td>9638.190407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zip_code</td>\n",
       "      <td>914</td>\n",
       "      <td>8783.496242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>record_time</td>\n",
       "      <td>880</td>\n",
       "      <td>11421.671202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balance</td>\n",
       "      <td>786</td>\n",
       "      <td>7670.18971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>level_default_ratio</td>\n",
       "      <td>762</td>\n",
       "      <td>14933.459477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balance_limit</td>\n",
       "      <td>726</td>\n",
       "      <td>8592.207829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>interest_rate_default_ratio</td>\n",
       "      <td>709</td>\n",
       "      <td>10860.658216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>balance_accounts</td>\n",
       "      <td>641</td>\n",
       "      <td>11247.360285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1_amount_avg2</td>\n",
       "      <td>640</td>\n",
       "      <td>5817.33879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_accounts</td>\n",
       "      <td>588</td>\n",
       "      <td>5482.359726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>total_amount_avg2</td>\n",
       "      <td>570</td>\n",
       "      <td>7050.55296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>record_time_week</td>\n",
       "      <td>560</td>\n",
       "      <td>4835.214161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>loan_term_avg</td>\n",
       "      <td>529</td>\n",
       "      <td>5083.176447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loan</td>\n",
       "      <td>488</td>\n",
       "      <td>4686.844246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0_amount_avg2</td>\n",
       "      <td>465</td>\n",
       "      <td>9761.663223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>record_time_year_month</td>\n",
       "      <td>462</td>\n",
       "      <td>4974.34106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>career</td>\n",
       "      <td>433</td>\n",
       "      <td>3856.61586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0_amount</td>\n",
       "      <td>416</td>\n",
       "      <td>4608.738836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tx_max_min_days</td>\n",
       "      <td>408</td>\n",
       "      <td>3812.636618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>407</td>\n",
       "      <td>5604.712368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tx_count</td>\n",
       "      <td>402</td>\n",
       "      <td>3993.778439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0_amount_avg</td>\n",
       "      <td>365</td>\n",
       "      <td>6600.707459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1_amount</td>\n",
       "      <td>362</td>\n",
       "      <td>3423.124446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tx_tmstp_max</td>\n",
       "      <td>358</td>\n",
       "      <td>5844.501965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>residence</td>\n",
       "      <td>352</td>\n",
       "      <td>5376.486742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>total_amount_avg</td>\n",
       "      <td>324</td>\n",
       "      <td>2961.490127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tx_count_avg</td>\n",
       "      <td>322</td>\n",
       "      <td>3048.706363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1_amount_avg</td>\n",
       "      <td>310</td>\n",
       "      <td>2876.046416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>total_amount</td>\n",
       "      <td>308</td>\n",
       "      <td>2941.853686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>tx_tmstp_min</td>\n",
       "      <td>275</td>\n",
       "      <td>4648.719397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>zip_province</td>\n",
       "      <td>269</td>\n",
       "      <td>3224.561259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>record_time_month</td>\n",
       "      <td>256</td>\n",
       "      <td>2196.145975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>zip_city</td>\n",
       "      <td>190</td>\n",
       "      <td>1760.661124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>term</td>\n",
       "      <td>132</td>\n",
       "      <td>12573.144093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>grade</td>\n",
       "      <td>113</td>\n",
       "      <td>1654.386905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>installment</td>\n",
       "      <td>60</td>\n",
       "      <td>491.32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>term_default_ratio</td>\n",
       "      <td>57</td>\n",
       "      <td>3925.404837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>level_A3</td>\n",
       "      <td>53</td>\n",
       "      <td>514.817262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>level_A4</td>\n",
       "      <td>52</td>\n",
       "      <td>483.389748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>record_time_year</td>\n",
       "      <td>49</td>\n",
       "      <td>544.79681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>level_A5</td>\n",
       "      <td>47</td>\n",
       "      <td>395.711011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>level_A2</td>\n",
       "      <td>43</td>\n",
       "      <td>448.416706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>level_B0</td>\n",
       "      <td>42</td>\n",
       "      <td>315.302819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>level_B1</td>\n",
       "      <td>37</td>\n",
       "      <td>273.35629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>level_B3</td>\n",
       "      <td>34</td>\n",
       "      <td>288.330309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>level_B2</td>\n",
       "      <td>33</td>\n",
       "      <td>307.019679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>level_B4</td>\n",
       "      <td>32</td>\n",
       "      <td>238.172038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>level_A0</td>\n",
       "      <td>28</td>\n",
       "      <td>316.55088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>syndicated</td>\n",
       "      <td>28</td>\n",
       "      <td>241.17919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>level_C3</td>\n",
       "      <td>23</td>\n",
       "      <td>191.58995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>level_A1</td>\n",
       "      <td>12</td>\n",
       "      <td>197.936273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>level_B5</td>\n",
       "      <td>10</td>\n",
       "      <td>84.15755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>level_C2</td>\n",
       "      <td>9</td>\n",
       "      <td>63.92262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>level_C1</td>\n",
       "      <td>8</td>\n",
       "      <td>57.29593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>level_D1</td>\n",
       "      <td>8</td>\n",
       "      <td>55.38021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>level_D2</td>\n",
       "      <td>8</td>\n",
       "      <td>65.26292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>level_C5</td>\n",
       "      <td>6</td>\n",
       "      <td>54.46903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>level_C4</td>\n",
       "      <td>4</td>\n",
       "      <td>30.68576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>level_E4</td>\n",
       "      <td>4</td>\n",
       "      <td>20.68243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>level_E1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.32943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>level_D5</td>\n",
       "      <td>1</td>\n",
       "      <td>7.75492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>level_E2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.87469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>level_D3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>level_D4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>level_E3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>level_E5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0     1             2\n",
       "7                    issue_time  1360  14490.952175\n",
       "6                 interest_rate  1322  23407.413197\n",
       "11                 history_time  1132  10093.139229\n",
       "44           loan_balance_ratio   977   8591.403071\n",
       "16          balance_account_avg   938   8452.008111\n",
       "18       balance_accounts_ratio   934   8927.602976\n",
       "43              loan_loan_ratio   924   9638.190407\n",
       "2                      zip_code   914   8783.496242\n",
       "10                  record_time   880  11421.671202\n",
       "15                      balance   786    7670.18971\n",
       "26          level_default_ratio   762  14933.459477\n",
       "14                balance_limit   726   8592.207829\n",
       "27  interest_rate_default_ratio   709  10860.658216\n",
       "13             balance_accounts   641  11247.360285\n",
       "38                1_amount_avg2   640    5817.33879\n",
       "12               total_accounts   588   5482.359726\n",
       "37            total_amount_avg2   570    7050.55296\n",
       "24             record_time_week   560   4835.214161\n",
       "17                loan_term_avg   529   5083.176447\n",
       "4                          loan   488   4686.844246\n",
       "39                0_amount_avg2   465   9761.663223\n",
       "25       record_time_year_month   462    4974.34106\n",
       "1                        career   433    3856.61586\n",
       "33                     0_amount   416   4608.738836\n",
       "29              tx_max_min_days   408   3812.636618\n",
       "0                         title   407   5604.712368\n",
       "30                     tx_count   402   3993.778439\n",
       "36                 0_amount_avg   365   6600.707459\n",
       "32                     1_amount   362   3423.124446\n",
       "41                 tx_tmstp_max   358   5844.501965\n",
       "3                     residence   352   5376.486742\n",
       "34             total_amount_avg   324   2961.490127\n",
       "40                 tx_count_avg   322   3048.706363\n",
       "35                 1_amount_avg   310   2876.046416\n",
       "31                 total_amount   308   2941.853686\n",
       "42                 tx_tmstp_min   275   4648.719397\n",
       "19                 zip_province   269   3224.561259\n",
       "23            record_time_month   256   2196.145975\n",
       "20                     zip_city   190   1760.661124\n",
       "5                          term   132  12573.144093\n",
       "21                        grade   113   1654.386905\n",
       "9                   installment    60     491.32067\n",
       "28           term_default_ratio    57   3925.404837\n",
       "48                     level_A3    53    514.817262\n",
       "49                     level_A4    52    483.389748\n",
       "22             record_time_year    49     544.79681\n",
       "50                     level_A5    47    395.711011\n",
       "47                     level_A2    43    448.416706\n",
       "51                     level_B0    42    315.302819\n",
       "52                     level_B1    37     273.35629\n",
       "54                     level_B3    34    288.330309\n",
       "53                     level_B2    33    307.019679\n",
       "55                     level_B4    32    238.172038\n",
       "45                     level_A0    28     316.55088\n",
       "8                    syndicated    28     241.17919\n",
       "59                     level_C3    23     191.58995\n",
       "46                     level_A1    12    197.936273\n",
       "56                     level_B5    10      84.15755\n",
       "58                     level_C2     9      63.92262\n",
       "57                     level_C1     8      57.29593\n",
       "62                     level_D1     8      55.38021\n",
       "63                     level_D2     8      65.26292\n",
       "61                     level_C5     6      54.46903\n",
       "60                     level_C4     4      30.68576\n",
       "70                     level_E4     4      20.68243\n",
       "67                     level_E1     2      19.32943\n",
       "66                     level_D5     1       7.75492\n",
       "68                     level_E2     1       7.87469\n",
       "64                     level_D3     0           0.0\n",
       "65                     level_D4     0           0.0\n",
       "69                     level_E3     0           0.0\n",
       "71                     level_E5     0           0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "idx = 1\n",
    "df_imp = pd.DataFrame([models[idx].feature_name(), models[idx].feature_importance(), models[idx].feature_importance(importance_type='gain')]).T\n",
    "df_imp.sort_values(by=1, ascending=False)\n",
    "\n",
    "# 重训模型\n",
    "# df_imp = pd.DataFrame([lgb_lgb_clf.feature_name(), lgb_lgb_clf.feature_importance(), lgb_lgb_clf.feature_importance(importance_type='gain')]).T\n",
    "# df_imp.sort_values(by=2,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51832b9d",
   "metadata": {},
   "source": [
    "# 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c556e519",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ret \n",
      "               0         1         2         3         4         5         6  \\\n",
      "0      0.085259  0.110634  0.117442  0.092115  0.103316  0.107331  0.109064   \n",
      "1      0.040393  0.042583  0.046514  0.044229  0.044535  0.039951  0.041874   \n",
      "2      0.133445  0.116952  0.146966  0.161797  0.126523  0.107135  0.135865   \n",
      "3      0.234347  0.226882  0.226697  0.239089  0.211855  0.220506  0.228315   \n",
      "4      0.113947  0.112256  0.111246  0.122076  0.125132  0.106414  0.127198   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "20049  0.207300  0.187192  0.191161  0.201292  0.186531  0.191221  0.195009   \n",
      "20050  0.100706  0.093844  0.106330  0.106629  0.099447  0.101003  0.103918   \n",
      "20051  0.199316  0.197881  0.188556  0.203644  0.199068  0.194911  0.182004   \n",
      "20052  0.192369  0.179890  0.178099  0.179589  0.183908  0.177898  0.186312   \n",
      "20053  0.204186  0.206589  0.200489  0.199859  0.196001  0.207589  0.201647   \n",
      "\n",
      "              7         8         9  \n",
      "0      0.106485  0.095143  0.095710  \n",
      "1      0.036873  0.048532  0.041437  \n",
      "2      0.125590  0.138541  0.155024  \n",
      "3      0.221421  0.236683  0.227202  \n",
      "4      0.114273  0.116204  0.108611  \n",
      "...         ...       ...       ...  \n",
      "20049  0.187821  0.192219  0.196771  \n",
      "20050  0.097836  0.102563  0.098179  \n",
      "20051  0.186959  0.184715  0.201609  \n",
      "20052  0.183104  0.185246  0.194843  \n",
      "20053  0.200043  0.226988  0.195652  \n",
      "\n",
      "[20054 rows x 10 columns]\n",
      "df_ans \n",
      "               0         1         2         3         4         5         6  \\\n",
      "0      0.085259  0.110634  0.117442  0.092115  0.103316  0.107331  0.109064   \n",
      "1      0.040393  0.042583  0.046514  0.044229  0.044535  0.039951  0.041874   \n",
      "2      0.133445  0.116952  0.146966  0.161797  0.126523  0.107135  0.135865   \n",
      "3      0.234347  0.226882  0.226697  0.239089  0.211855  0.220506  0.228315   \n",
      "4      0.113947  0.112256  0.111246  0.122076  0.125132  0.106414  0.127198   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "20049  0.207300  0.187192  0.191161  0.201292  0.186531  0.191221  0.195009   \n",
      "20050  0.100706  0.093844  0.106330  0.106629  0.099447  0.101003  0.103918   \n",
      "20051  0.199316  0.197881  0.188556  0.203644  0.199068  0.194911  0.182004   \n",
      "20052  0.192369  0.179890  0.178099  0.179589  0.183908  0.177898  0.186312   \n",
      "20053  0.204186  0.206589  0.200489  0.199859  0.196001  0.207589  0.201647   \n",
      "\n",
      "              7         8         9     label     id  \n",
      "0      0.106485  0.095143  0.095710  0.102250  53480  \n",
      "1      0.036873  0.048532  0.041437  0.042692  53481  \n",
      "2      0.125590  0.138541  0.155024  0.134784  53482  \n",
      "3      0.221421  0.236683  0.227202  0.227300  53483  \n",
      "4      0.114273  0.116204  0.108611  0.115736  53484  \n",
      "...         ...       ...       ...       ...    ...  \n",
      "20049  0.187821  0.192219  0.196771  0.193652  73529  \n",
      "20050  0.097836  0.102563  0.098179  0.101046  73530  \n",
      "20051  0.186959  0.184715  0.201609  0.193866  73531  \n",
      "20052  0.183104  0.185246  0.194843  0.184126  73532  \n",
      "20053  0.200043  0.226988  0.195652  0.203904  73533  \n",
      "\n",
      "[20054 rows x 12 columns]\n",
      "df_out \n",
      "           id     label\n",
      "0      53480  0.102250\n",
      "1      53481  0.042692\n",
      "2      53482  0.134784\n",
      "3      53483  0.227300\n",
      "4      53484  0.115736\n",
      "...      ...       ...\n",
      "20049  73529  0.193652\n",
      "20050  73530  0.101046\n",
      "20051  73531  0.193866\n",
      "20052  73532  0.184126\n",
      "20053  73533  0.203904\n",
      "\n",
      "[20054 rows x 2 columns]\n",
      "bak\n",
      "model_gbdt_v23.ipynb\n",
      "model_lgb_v23.ipynb\n",
      "model_xgb_v23.ipynb\n",
      "process_v23.ipynb\n",
      "test.dat.v23\n",
      "train.dat.v23\n",
      "v23_gh_lgb_10folds_mean_v23.csv\n",
      "v23_gh_lgb_10folds_mean_v23_ans.txt\n",
      "v23_gh_lgb_10folds_mean_v23_ret.txt\n"
     ]
    }
   ],
   "source": [
    "def save_result(df_ans, fout_name):\n",
    "    #保存结果\n",
    "    df_ans['label'] = df_ans.mean(axis = 1)\n",
    "    df_ans['id'] = pd.DataFrame({'id':X_test_test.index.values})[['id']]\n",
    "    print('df_ans \\n',df_ans)\n",
    "    df_out = df_ans[['id','label']]\n",
    "    print('df_out \\n',df_out)\n",
    "    df_out.to_csv('%s.csv' % fout_name, encoding='utf-8', index=False, mode='w')\n",
    "    df_ans.to_csv('%s_ans.txt' % fout_name, encoding='utf-8', index=False, mode='w')\n",
    "    df_ret.to_csv('%s_ret.txt' % fout_name, encoding='utf-8', index=False, mode='w')\n",
    "    !ls\n",
    "\n",
    "# -------------------------------------------------------------- #\n",
    "\n",
    "df_ret = pd.DataFrame(answers).T\n",
    "print('df_ret \\n',df_ret)\n",
    "df_ans = df_ret.loc[:, :]\n",
    "save_result(df_ans, '%s_gh_lgb_10folds_mean_v23' % suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a121754c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stat_result(pred):\n",
    "    ret = pd.DataFrame({'label' : pred})\n",
    "    df_ret = ret.groupby(pd.cut(pred, bins=20))['label'].agg('count')\n",
    "    df_ret.plot(kind='bar')\n",
    "    \n",
    "\n",
    "# df_ret[[3]]\n",
    "stat_result(test_test_pred)\n",
    "# pd.cut(df_ret[3], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c85c9",
   "metadata": {},
   "source": [
    "# 后续忽略 -----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f83883",
   "metadata": {},
   "source": [
    "# LGB MODEL1  指定种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3fda5b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.678407\tvalid_1's auc: 0.666936\n",
      "[200]\ttraining's auc: 0.69525\tvalid_1's auc: 0.66809\n",
      "[300]\ttraining's auc: 0.711577\tvalid_1's auc: 0.670378\n",
      "[400]\ttraining's auc: 0.727443\tvalid_1's auc: 0.671832\n",
      "[500]\ttraining's auc: 0.742603\tvalid_1's auc: 0.672062\n",
      "[600]\ttraining's auc: 0.754129\tvalid_1's auc: 0.672752\n",
      "[700]\ttraining's auc: 0.767405\tvalid_1's auc: 0.672659\n",
      "[800]\ttraining's auc: 0.777929\tvalid_1's auc: 0.6734\n",
      "[900]\ttraining's auc: 0.787718\tvalid_1's auc: 0.673863\n",
      "[1000]\ttraining's auc: 0.797312\tvalid_1's auc: 0.674153\n",
      "[1100]\ttraining's auc: 0.806258\tvalid_1's auc: 0.673914\n",
      "[1200]\ttraining's auc: 0.815365\tvalid_1's auc: 0.673347\n",
      "[1300]\ttraining's auc: 0.823445\tvalid_1's auc: 0.673878\n",
      "[1400]\ttraining's auc: 0.831077\tvalid_1's auc: 0.673868\n",
      "[1500]\ttraining's auc: 0.838315\tvalid_1's auc: 0.673653\n",
      "[1600]\ttraining's auc: 0.844752\tvalid_1's auc: 0.674048\n",
      "[1700]\ttraining's auc: 0.852143\tvalid_1's auc: 0.67474\n",
      "[1800]\ttraining's auc: 0.85786\tvalid_1's auc: 0.674951\n",
      "[1900]\ttraining's auc: 0.863995\tvalid_1's auc: 0.675424\n",
      "[2000]\ttraining's auc: 0.870755\tvalid_1's auc: 0.6756\n",
      "----------------------------- the 4 epoch lgb_model valid auc ---------------------  0.870755443854422 0.6756001763771744\n",
      "final pred  [0.07505858 0.02286054 0.13189564 ... 0.19825928 0.18934292 0.24124289]\n",
      "[100]\ttraining's auc: 0.676469\tvalid_1's auc: 0.670956\n",
      "[200]\ttraining's auc: 0.697173\tvalid_1's auc: 0.675883\n",
      "[300]\ttraining's auc: 0.713023\tvalid_1's auc: 0.676941\n",
      "[400]\ttraining's auc: 0.727461\tvalid_1's auc: 0.678398\n",
      "[500]\ttraining's auc: 0.740993\tvalid_1's auc: 0.678615\n",
      "[600]\ttraining's auc: 0.754501\tvalid_1's auc: 0.679195\n",
      "[700]\ttraining's auc: 0.766791\tvalid_1's auc: 0.678787\n",
      "[800]\ttraining's auc: 0.777549\tvalid_1's auc: 0.678682\n",
      "[900]\ttraining's auc: 0.788002\tvalid_1's auc: 0.679173\n",
      "[1000]\ttraining's auc: 0.798145\tvalid_1's auc: 0.678446\n",
      "[1100]\ttraining's auc: 0.806984\tvalid_1's auc: 0.678227\n",
      "[1200]\ttraining's auc: 0.816112\tvalid_1's auc: 0.678214\n",
      "[1300]\ttraining's auc: 0.824319\tvalid_1's auc: 0.678483\n",
      "[1400]\ttraining's auc: 0.832172\tvalid_1's auc: 0.678329\n",
      "[1500]\ttraining's auc: 0.839305\tvalid_1's auc: 0.678141\n",
      "[1600]\ttraining's auc: 0.84662\tvalid_1's auc: 0.678384\n",
      "[1700]\ttraining's auc: 0.85359\tvalid_1's auc: 0.678425\n",
      "[1800]\ttraining's auc: 0.860206\tvalid_1's auc: 0.677624\n",
      "[1900]\ttraining's auc: 0.865921\tvalid_1's auc: 0.677945\n",
      "[2000]\ttraining's auc: 0.871859\tvalid_1's auc: 0.678439\n",
      "----------------------------- the 4 epoch lgb_model valid auc ---------------------  0.8718592542160568 0.6784387326079343\n",
      "final pred  [0.11198654 0.03555866 0.16343769 ... 0.18732799 0.19839211 0.21387686]\n",
      "[100]\ttraining's auc: 0.679849\tvalid_1's auc: 0.665032\n",
      "[200]\ttraining's auc: 0.698945\tvalid_1's auc: 0.666793\n",
      "[300]\ttraining's auc: 0.713145\tvalid_1's auc: 0.665093\n",
      "[400]\ttraining's auc: 0.728028\tvalid_1's auc: 0.664606\n",
      "[500]\ttraining's auc: 0.742408\tvalid_1's auc: 0.664746\n",
      "[600]\ttraining's auc: 0.757119\tvalid_1's auc: 0.664515\n",
      "[700]\ttraining's auc: 0.768564\tvalid_1's auc: 0.664237\n",
      "[800]\ttraining's auc: 0.780595\tvalid_1's auc: 0.663939\n",
      "[900]\ttraining's auc: 0.791201\tvalid_1's auc: 0.664339\n",
      "[1000]\ttraining's auc: 0.801048\tvalid_1's auc: 0.663846\n",
      "[1100]\ttraining's auc: 0.810248\tvalid_1's auc: 0.664363\n",
      "[1200]\ttraining's auc: 0.820175\tvalid_1's auc: 0.664954\n",
      "[1300]\ttraining's auc: 0.828495\tvalid_1's auc: 0.664804\n",
      "[1400]\ttraining's auc: 0.835409\tvalid_1's auc: 0.664688\n",
      "[1500]\ttraining's auc: 0.842802\tvalid_1's auc: 0.6648\n",
      "[1600]\ttraining's auc: 0.849268\tvalid_1's auc: 0.665118\n",
      "[1700]\ttraining's auc: 0.856086\tvalid_1's auc: 0.665321\n",
      "[1800]\ttraining's auc: 0.862075\tvalid_1's auc: 0.664434\n",
      "[1900]\ttraining's auc: 0.867912\tvalid_1's auc: 0.664187\n",
      "[2000]\ttraining's auc: 0.873482\tvalid_1's auc: 0.663425\n",
      "----------------------------- the 4 epoch lgb_model valid auc ---------------------  0.8734824050860295 0.6634246506236162\n",
      "final pred  [0.09338573 0.02760191 0.12786908 ... 0.21190114 0.20105041 0.2252082 ]\n",
      "auc arr \n",
      "    train auc  test_auc\n",
      "0   0.870755  0.675600\n",
      "1   0.871859  0.678439\n",
      "2   0.873482  0.663425\n",
      "auc describe \n",
      "               0         1\n",
      "count  3.000000  3.000000\n",
      "mean   0.872032  0.672488\n",
      "std    0.001372  0.007976\n",
      "min    0.870755  0.663425\n",
      "25%    0.871307  0.669512\n",
      "50%    0.871859  0.675600\n",
      "75%    0.872671  0.677019\n",
      "max    0.873482  0.678439\n",
      "answers  (3, 20054)\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "auc_arr = [] \n",
    "import random\n",
    "random.seed(a=10)\n",
    "sedd_arr = random.sample(range(1,10000), 5)\n",
    "# for seed in  [10, 11, 100, 1000, 2025, 1989]:\n",
    "# for i, seed in enumerate(sedd_arr):\n",
    "for seed in  [10, 11, 1989]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_train, y_train_train, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    #lgb model \n",
    "    lgb_clf, test_pred = lgb_feature(X_train, y_train, X_test, y_test)\n",
    "    train_pred = lgb_clf.predict(X_train)\n",
    "    # train auc, test auc\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc  = roc_auc_score(y_test, test_pred)\n",
    "    print('----------------------------- the %d epoch lgb_model valid auc --------------------- ' % i, train_auc, test_auc)\n",
    "    auc_arr.append((train_auc, test_auc))\n",
    "    #最终输出\n",
    "    final_pred = lgb_clf.predict(X_test_test)\n",
    "    print('final pred ',final_pred)\n",
    "    answers.append(final_pred)\n",
    "print('auc arr \\n', pd.DataFrame(auc_arr, columns=['train auc', 'test_auc']))\n",
    "print('auc describe \\n', pd.DataFrame(auc_arr).describe())\n",
    "print('answers ', np.array(answers).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267973a0",
   "metadata": {},
   "source": [
    "# LGB model1 test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0205cb53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.679203\tvalid_1's auc: 0.653807\n",
      "[200]\ttraining's auc: 0.694417\tvalid_1's auc: 0.654399\n",
      "[300]\ttraining's auc: 0.709002\tvalid_1's auc: 0.655899\n",
      "[400]\ttraining's auc: 0.722636\tvalid_1's auc: 0.656784\n",
      "[500]\ttraining's auc: 0.734649\tvalid_1's auc: 0.657503\n",
      "[600]\ttraining's auc: 0.747498\tvalid_1's auc: 0.657854\n",
      "[700]\ttraining's auc: 0.760004\tvalid_1's auc: 0.658605\n",
      "[800]\ttraining's auc: 0.770616\tvalid_1's auc: 0.65899\n",
      "[900]\ttraining's auc: 0.779914\tvalid_1's auc: 0.658916\n",
      "[1000]\ttraining's auc: 0.788272\tvalid_1's auc: 0.658474\n",
      "[1100]\ttraining's auc: 0.797283\tvalid_1's auc: 0.657742\n",
      "[1200]\ttraining's auc: 0.805969\tvalid_1's auc: 0.658578\n",
      "[1300]\ttraining's auc: 0.814643\tvalid_1's auc: 0.658908\n",
      "[1400]\ttraining's auc: 0.82179\tvalid_1's auc: 0.659433\n",
      "[1500]\ttraining's auc: 0.82881\tvalid_1's auc: 0.659879\n",
      "[1600]\ttraining's auc: 0.835806\tvalid_1's auc: 0.659972\n",
      "[1700]\ttraining's auc: 0.842795\tvalid_1's auc: 0.659692\n",
      "[1800]\ttraining's auc: 0.849006\tvalid_1's auc: 0.659743\n",
      "[1900]\ttraining's auc: 0.855396\tvalid_1's auc: 0.659445\n",
      "[2000]\ttraining's auc: 0.860495\tvalid_1's auc: 0.659008\n",
      "----------------------------- the 0 epoch lgb_model valid auc ---------------------  0.8604951837826709 0.6590078434967359\n",
      "final pred  [0.08505691 0.02930154 0.10015635 ... 0.18274636 0.17942201 0.21298747]\n",
      "[100]\ttraining's auc: 0.675943\tvalid_1's auc: 0.656833\n",
      "[200]\ttraining's auc: 0.694958\tvalid_1's auc: 0.658382\n",
      "[300]\ttraining's auc: 0.708618\tvalid_1's auc: 0.658501\n",
      "[400]\ttraining's auc: 0.723257\tvalid_1's auc: 0.66174\n",
      "[500]\ttraining's auc: 0.735631\tvalid_1's auc: 0.662103\n",
      "[600]\ttraining's auc: 0.748047\tvalid_1's auc: 0.662833\n",
      "[700]\ttraining's auc: 0.759179\tvalid_1's auc: 0.663638\n",
      "[800]\ttraining's auc: 0.771405\tvalid_1's auc: 0.663529\n",
      "[900]\ttraining's auc: 0.780195\tvalid_1's auc: 0.664423\n",
      "[1000]\ttraining's auc: 0.788503\tvalid_1's auc: 0.664682\n",
      "[1100]\ttraining's auc: 0.796966\tvalid_1's auc: 0.664466\n",
      "[1200]\ttraining's auc: 0.805592\tvalid_1's auc: 0.665776\n",
      "[1300]\ttraining's auc: 0.813152\tvalid_1's auc: 0.665742\n",
      "[1400]\ttraining's auc: 0.820479\tvalid_1's auc: 0.666273\n",
      "[1500]\ttraining's auc: 0.827902\tvalid_1's auc: 0.66658\n",
      "[1600]\ttraining's auc: 0.834414\tvalid_1's auc: 0.66753\n",
      "[1700]\ttraining's auc: 0.841394\tvalid_1's auc: 0.667052\n",
      "[1800]\ttraining's auc: 0.847214\tvalid_1's auc: 0.667805\n",
      "[1900]\ttraining's auc: 0.85387\tvalid_1's auc: 0.667931\n",
      "[2000]\ttraining's auc: 0.858663\tvalid_1's auc: 0.667798\n",
      "----------------------------- the 1 epoch lgb_model valid auc ---------------------  0.8586628328010565 0.6677980666970526\n",
      "final pred  [0.09316398 0.03612884 0.08648524 ... 0.19541149 0.18606789 0.19221575]\n",
      "[100]\ttraining's auc: 0.677976\tvalid_1's auc: 0.650037\n",
      "[200]\ttraining's auc: 0.694153\tvalid_1's auc: 0.652809\n",
      "[300]\ttraining's auc: 0.708868\tvalid_1's auc: 0.656872\n",
      "[400]\ttraining's auc: 0.722545\tvalid_1's auc: 0.659107\n",
      "[500]\ttraining's auc: 0.735634\tvalid_1's auc: 0.659436\n",
      "[600]\ttraining's auc: 0.747451\tvalid_1's auc: 0.659871\n",
      "[700]\ttraining's auc: 0.758428\tvalid_1's auc: 0.660451\n",
      "[800]\ttraining's auc: 0.769231\tvalid_1's auc: 0.660625\n",
      "[900]\ttraining's auc: 0.780707\tvalid_1's auc: 0.660333\n",
      "[1000]\ttraining's auc: 0.789951\tvalid_1's auc: 0.66049\n",
      "[1100]\ttraining's auc: 0.799066\tvalid_1's auc: 0.661502\n",
      "[1200]\ttraining's auc: 0.807433\tvalid_1's auc: 0.66197\n",
      "[1300]\ttraining's auc: 0.815731\tvalid_1's auc: 0.661631\n",
      "[1400]\ttraining's auc: 0.822784\tvalid_1's auc: 0.661255\n",
      "[1500]\ttraining's auc: 0.829967\tvalid_1's auc: 0.662228\n",
      "[1600]\ttraining's auc: 0.835957\tvalid_1's auc: 0.662398\n",
      "[1700]\ttraining's auc: 0.842431\tvalid_1's auc: 0.66231\n",
      "[1800]\ttraining's auc: 0.849216\tvalid_1's auc: 0.663041\n",
      "[1900]\ttraining's auc: 0.854716\tvalid_1's auc: 0.662594\n",
      "[2000]\ttraining's auc: 0.86019\tvalid_1's auc: 0.663203\n",
      "----------------------------- the 2 epoch lgb_model valid auc ---------------------  0.8601896399294297 0.6632029267429113\n",
      "final pred  [0.06538606 0.02589982 0.11843092 ... 0.18178056 0.18982779 0.21153445]\n",
      "[100]\ttraining's auc: 0.676831\tvalid_1's auc: 0.657945\n",
      "[200]\ttraining's auc: 0.692646\tvalid_1's auc: 0.655272\n",
      "[300]\ttraining's auc: 0.70773\tvalid_1's auc: 0.657337\n",
      "[400]\ttraining's auc: 0.722405\tvalid_1's auc: 0.657094\n",
      "[500]\ttraining's auc: 0.735837\tvalid_1's auc: 0.656977\n",
      "[600]\ttraining's auc: 0.749235\tvalid_1's auc: 0.657235\n",
      "[700]\ttraining's auc: 0.76081\tvalid_1's auc: 0.655851\n",
      "[800]\ttraining's auc: 0.771663\tvalid_1's auc: 0.655193\n",
      "[900]\ttraining's auc: 0.78145\tvalid_1's auc: 0.655198\n",
      "[1000]\ttraining's auc: 0.790775\tvalid_1's auc: 0.655905\n",
      "[1100]\ttraining's auc: 0.799711\tvalid_1's auc: 0.655813\n",
      "[1200]\ttraining's auc: 0.807568\tvalid_1's auc: 0.656765\n",
      "[1300]\ttraining's auc: 0.815749\tvalid_1's auc: 0.656762\n",
      "[1400]\ttraining's auc: 0.822767\tvalid_1's auc: 0.656361\n",
      "[1500]\ttraining's auc: 0.829509\tvalid_1's auc: 0.657048\n",
      "[1600]\ttraining's auc: 0.837218\tvalid_1's auc: 0.656763\n",
      "[1700]\ttraining's auc: 0.843644\tvalid_1's auc: 0.655781\n",
      "[1800]\ttraining's auc: 0.850146\tvalid_1's auc: 0.654839\n",
      "[1900]\ttraining's auc: 0.855675\tvalid_1's auc: 0.654854\n",
      "[2000]\ttraining's auc: 0.860745\tvalid_1's auc: 0.655201\n",
      "----------------------------- the 3 epoch lgb_model valid auc ---------------------  0.8607452339241786 0.6552012715042072\n",
      "final pred  [0.08064256 0.0281185  0.10240335 ... 0.21140841 0.20304843 0.26263766]\n",
      "[100]\ttraining's auc: 0.679068\tvalid_1's auc: 0.653082\n",
      "[200]\ttraining's auc: 0.695757\tvalid_1's auc: 0.653625\n",
      "[300]\ttraining's auc: 0.709258\tvalid_1's auc: 0.654058\n",
      "[400]\ttraining's auc: 0.721799\tvalid_1's auc: 0.655148\n",
      "[500]\ttraining's auc: 0.73381\tvalid_1's auc: 0.655773\n",
      "[600]\ttraining's auc: 0.746542\tvalid_1's auc: 0.656852\n",
      "[700]\ttraining's auc: 0.757477\tvalid_1's auc: 0.656972\n",
      "[800]\ttraining's auc: 0.767262\tvalid_1's auc: 0.657629\n",
      "[900]\ttraining's auc: 0.776774\tvalid_1's auc: 0.65836\n",
      "[1000]\ttraining's auc: 0.785428\tvalid_1's auc: 0.657234\n",
      "[1100]\ttraining's auc: 0.795606\tvalid_1's auc: 0.657317\n",
      "[1200]\ttraining's auc: 0.805195\tvalid_1's auc: 0.65767\n",
      "[1300]\ttraining's auc: 0.812726\tvalid_1's auc: 0.657243\n",
      "[1400]\ttraining's auc: 0.819848\tvalid_1's auc: 0.656931\n",
      "[1500]\ttraining's auc: 0.827602\tvalid_1's auc: 0.658019\n",
      "[1600]\ttraining's auc: 0.833834\tvalid_1's auc: 0.657891\n",
      "[1700]\ttraining's auc: 0.839904\tvalid_1's auc: 0.657622\n",
      "[1800]\ttraining's auc: 0.846654\tvalid_1's auc: 0.657614\n",
      "[1900]\ttraining's auc: 0.85288\tvalid_1's auc: 0.6576\n",
      "[2000]\ttraining's auc: 0.858903\tvalid_1's auc: 0.6569\n",
      "----------------------------- the 4 epoch lgb_model valid auc ---------------------  0.8589030995115012 0.6569003495600048\n",
      "final pred  [0.07652603 0.03110131 0.12513166 ... 0.19924497 0.19978477 0.21485367]\n",
      "auc arr \n",
      "    train auc  test_auc\n",
      "0   0.860495  0.659008\n",
      "1   0.858663  0.667798\n",
      "2   0.860190  0.663203\n",
      "3   0.860745  0.655201\n",
      "4   0.858903  0.656900\n",
      "auc describe \n",
      "               0         1\n",
      "count  5.000000  5.000000\n",
      "mean   0.859799  0.660422\n",
      "std    0.000952  0.005094\n",
      "min    0.858663  0.655201\n",
      "25%    0.858903  0.656900\n",
      "50%    0.860190  0.659008\n",
      "75%    0.860495  0.663203\n",
      "max    0.860745  0.667798\n",
      "answers  (5, 20054)\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "auc_arr = [] \n",
    "import random\n",
    "random.seed(a=10)\n",
    "sedd_arr = random.sample(range(1,10000), 5)\n",
    "# for seed in  [10, 11, 100, 1000, 2025, 1989]:\n",
    "# for seed in  [10, 11, 1989]:\n",
    "for i, seed in enumerate(sedd_arr):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_train, y_train_train, test_size=0.1, random_state=seed, shuffle=True)\n",
    "    #lgb model \n",
    "    lgb_clf, test_pred = lgb_feature(X_train, y_train, X_test, y_test)\n",
    "    train_pred = lgb_clf.predict(X_train)\n",
    "    # train auc, test auc\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc  = roc_auc_score(y_test, test_pred)\n",
    "    print('----------------------------- the %d epoch lgb_model valid auc --------------------- ' % i, train_auc, test_auc)\n",
    "    auc_arr.append((train_auc, test_auc))\n",
    "    #最终输出\n",
    "    final_pred = lgb_clf.predict(X_test_test)\n",
    "    print('final pred ',final_pred)\n",
    "    answers.append(final_pred)\n",
    "print('auc arr \\n', pd.DataFrame(auc_arr, columns=['train auc', 'test_auc']))\n",
    "print('auc describe \\n', pd.DataFrame(auc_arr).describe())\n",
    "print('answers ', np.array(answers).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f751d3",
   "metadata": {},
   "source": [
    "# LGB MODEL1  随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d7e2af7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.681637\tvalid_1's auc: 0.650021\n",
      "[200]\ttraining's auc: 0.696665\tvalid_1's auc: 0.651322\n",
      "[300]\ttraining's auc: 0.713113\tvalid_1's auc: 0.651536\n",
      "[400]\ttraining's auc: 0.729707\tvalid_1's auc: 0.652245\n",
      "[500]\ttraining's auc: 0.744224\tvalid_1's auc: 0.652089\n",
      "[600]\ttraining's auc: 0.757229\tvalid_1's auc: 0.65323\n",
      "[700]\ttraining's auc: 0.768326\tvalid_1's auc: 0.653753\n",
      "[800]\ttraining's auc: 0.779889\tvalid_1's auc: 0.653981\n",
      "[900]\ttraining's auc: 0.790473\tvalid_1's auc: 0.654483\n",
      "[1000]\ttraining's auc: 0.800583\tvalid_1's auc: 0.654936\n",
      "[1100]\ttraining's auc: 0.80996\tvalid_1's auc: 0.655081\n",
      "[1200]\ttraining's auc: 0.818379\tvalid_1's auc: 0.655063\n",
      "[1300]\ttraining's auc: 0.82598\tvalid_1's auc: 0.654301\n",
      "[1400]\ttraining's auc: 0.834068\tvalid_1's auc: 0.654252\n",
      "[1500]\ttraining's auc: 0.842141\tvalid_1's auc: 0.653645\n",
      "[1600]\ttraining's auc: 0.84896\tvalid_1's auc: 0.653617\n",
      "[1700]\ttraining's auc: 0.855658\tvalid_1's auc: 0.653014\n",
      "[1800]\ttraining's auc: 0.861376\tvalid_1's auc: 0.653259\n",
      "[1900]\ttraining's auc: 0.867273\tvalid_1's auc: 0.652864\n",
      "[2000]\ttraining's auc: 0.873287\tvalid_1's auc: 0.652694\n",
      "----------------------------- the 0 epoch lgb_model valid auc ---------------------  0.8732874278223168 0.6526941814663811\n",
      "final pred  [0.08680678 0.0345153  0.11564151 ... 0.17949018 0.17853045 0.18656031]\n",
      "[100]\ttraining's auc: 0.679932\tvalid_1's auc: 0.654658\n",
      "[200]\ttraining's auc: 0.696386\tvalid_1's auc: 0.658735\n",
      "[300]\ttraining's auc: 0.713395\tvalid_1's auc: 0.659167\n",
      "[400]\ttraining's auc: 0.728173\tvalid_1's auc: 0.660635\n",
      "[500]\ttraining's auc: 0.741064\tvalid_1's auc: 0.659984\n",
      "[600]\ttraining's auc: 0.754642\tvalid_1's auc: 0.660013\n",
      "[700]\ttraining's auc: 0.767173\tvalid_1's auc: 0.659639\n",
      "[800]\ttraining's auc: 0.778761\tvalid_1's auc: 0.660243\n",
      "[900]\ttraining's auc: 0.789869\tvalid_1's auc: 0.659974\n",
      "[1000]\ttraining's auc: 0.800294\tvalid_1's auc: 0.659577\n",
      "[1100]\ttraining's auc: 0.809554\tvalid_1's auc: 0.659025\n",
      "[1200]\ttraining's auc: 0.81867\tvalid_1's auc: 0.659005\n",
      "[1300]\ttraining's auc: 0.826169\tvalid_1's auc: 0.659488\n",
      "[1400]\ttraining's auc: 0.833427\tvalid_1's auc: 0.659959\n",
      "[1500]\ttraining's auc: 0.840638\tvalid_1's auc: 0.659732\n",
      "[1600]\ttraining's auc: 0.847416\tvalid_1's auc: 0.659394\n",
      "[1700]\ttraining's auc: 0.853807\tvalid_1's auc: 0.659181\n",
      "[1800]\ttraining's auc: 0.859651\tvalid_1's auc: 0.659096\n",
      "[1900]\ttraining's auc: 0.865276\tvalid_1's auc: 0.658946\n",
      "[2000]\ttraining's auc: 0.871128\tvalid_1's auc: 0.659017\n",
      "----------------------------- the 1 epoch lgb_model valid auc ---------------------  0.8711276918448706 0.6590166460693876\n",
      "final pred  [0.08042359 0.03264587 0.11158206 ... 0.1935975  0.18345028 0.18793309]\n",
      "[100]\ttraining's auc: 0.680742\tvalid_1's auc: 0.649429\n",
      "[200]\ttraining's auc: 0.699874\tvalid_1's auc: 0.654207\n",
      "[300]\ttraining's auc: 0.714619\tvalid_1's auc: 0.655032\n",
      "[400]\ttraining's auc: 0.731525\tvalid_1's auc: 0.657484\n",
      "[500]\ttraining's auc: 0.744336\tvalid_1's auc: 0.657923\n",
      "[600]\ttraining's auc: 0.75847\tvalid_1's auc: 0.659047\n",
      "[700]\ttraining's auc: 0.770959\tvalid_1's auc: 0.661268\n",
      "[800]\ttraining's auc: 0.782004\tvalid_1's auc: 0.660423\n",
      "[900]\ttraining's auc: 0.793029\tvalid_1's auc: 0.659348\n",
      "[1000]\ttraining's auc: 0.802552\tvalid_1's auc: 0.65924\n",
      "[1100]\ttraining's auc: 0.811409\tvalid_1's auc: 0.659717\n",
      "[1200]\ttraining's auc: 0.819724\tvalid_1's auc: 0.660488\n",
      "[1300]\ttraining's auc: 0.828122\tvalid_1's auc: 0.661348\n",
      "[1400]\ttraining's auc: 0.836203\tvalid_1's auc: 0.661603\n",
      "[1500]\ttraining's auc: 0.842903\tvalid_1's auc: 0.66263\n",
      "[1600]\ttraining's auc: 0.849555\tvalid_1's auc: 0.662367\n",
      "[1700]\ttraining's auc: 0.855985\tvalid_1's auc: 0.662124\n",
      "[1800]\ttraining's auc: 0.861562\tvalid_1's auc: 0.66188\n",
      "[1900]\ttraining's auc: 0.868159\tvalid_1's auc: 0.661418\n",
      "[2000]\ttraining's auc: 0.874159\tvalid_1's auc: 0.660567\n",
      "----------------------------- the 2 epoch lgb_model valid auc ---------------------  0.8741586459594881 0.6605668411339572\n",
      "final pred  [0.05863522 0.03062297 0.10645378 ... 0.20231845 0.18896007 0.20783822]\n",
      "[100]\ttraining's auc: 0.682462\tvalid_1's auc: 0.664775\n",
      "[200]\ttraining's auc: 0.697877\tvalid_1's auc: 0.665917\n",
      "[300]\ttraining's auc: 0.714272\tvalid_1's auc: 0.667654\n",
      "[400]\ttraining's auc: 0.730102\tvalid_1's auc: 0.666972\n",
      "[500]\ttraining's auc: 0.744157\tvalid_1's auc: 0.667338\n",
      "[600]\ttraining's auc: 0.757716\tvalid_1's auc: 0.666685\n",
      "[700]\ttraining's auc: 0.770375\tvalid_1's auc: 0.666923\n",
      "[800]\ttraining's auc: 0.781653\tvalid_1's auc: 0.66678\n",
      "[900]\ttraining's auc: 0.79279\tvalid_1's auc: 0.666056\n",
      "[1000]\ttraining's auc: 0.802506\tvalid_1's auc: 0.666179\n",
      "[1100]\ttraining's auc: 0.811291\tvalid_1's auc: 0.666797\n",
      "[1200]\ttraining's auc: 0.82152\tvalid_1's auc: 0.667189\n",
      "[1300]\ttraining's auc: 0.829674\tvalid_1's auc: 0.666672\n",
      "[1400]\ttraining's auc: 0.837152\tvalid_1's auc: 0.667226\n",
      "[1500]\ttraining's auc: 0.844085\tvalid_1's auc: 0.667339\n",
      "[1600]\ttraining's auc: 0.851365\tvalid_1's auc: 0.666874\n",
      "[1700]\ttraining's auc: 0.857629\tvalid_1's auc: 0.666963\n",
      "[1800]\ttraining's auc: 0.864235\tvalid_1's auc: 0.666413\n",
      "[1900]\ttraining's auc: 0.869769\tvalid_1's auc: 0.665703\n",
      "[2000]\ttraining's auc: 0.875819\tvalid_1's auc: 0.665823\n",
      "----------------------------- the 3 epoch lgb_model valid auc ---------------------  0.8758191358225783 0.6658232401884175\n",
      "final pred  [0.06255689 0.02744241 0.08104222 ... 0.22629627 0.20394618 0.21147085]\n",
      "[100]\ttraining's auc: 0.681595\tvalid_1's auc: 0.654748\n",
      "[200]\ttraining's auc: 0.697837\tvalid_1's auc: 0.656922\n",
      "[300]\ttraining's auc: 0.714283\tvalid_1's auc: 0.65829\n",
      "[400]\ttraining's auc: 0.73087\tvalid_1's auc: 0.660134\n",
      "[500]\ttraining's auc: 0.745401\tvalid_1's auc: 0.661236\n",
      "[600]\ttraining's auc: 0.758732\tvalid_1's auc: 0.662013\n",
      "[700]\ttraining's auc: 0.769623\tvalid_1's auc: 0.662489\n",
      "[800]\ttraining's auc: 0.782263\tvalid_1's auc: 0.662624\n",
      "[900]\ttraining's auc: 0.792935\tvalid_1's auc: 0.662062\n",
      "[1000]\ttraining's auc: 0.802239\tvalid_1's auc: 0.661568\n",
      "[1100]\ttraining's auc: 0.811209\tvalid_1's auc: 0.661417\n",
      "[1200]\ttraining's auc: 0.820186\tvalid_1's auc: 0.662229\n",
      "[1300]\ttraining's auc: 0.828202\tvalid_1's auc: 0.662172\n",
      "[1400]\ttraining's auc: 0.835601\tvalid_1's auc: 0.662028\n",
      "[1500]\ttraining's auc: 0.842223\tvalid_1's auc: 0.662061\n",
      "[1600]\ttraining's auc: 0.850026\tvalid_1's auc: 0.661957\n",
      "[1700]\ttraining's auc: 0.856158\tvalid_1's auc: 0.662085\n",
      "[1800]\ttraining's auc: 0.862574\tvalid_1's auc: 0.66212\n",
      "[1900]\ttraining's auc: 0.868852\tvalid_1's auc: 0.661845\n",
      "[2000]\ttraining's auc: 0.874938\tvalid_1's auc: 0.661522\n",
      "----------------------------- the 4 epoch lgb_model valid auc ---------------------  0.8749383604897336 0.6615223708778482\n",
      "final pred  [0.07969357 0.02335147 0.1586985  ... 0.19644669 0.18944162 0.1867195 ]\n",
      "auc arr \n",
      "    train auc  test_auc\n",
      "0   0.873287  0.652694\n",
      "1   0.871128  0.659017\n",
      "2   0.874159  0.660567\n",
      "3   0.875819  0.665823\n",
      "4   0.874938  0.661522\n",
      "auc describe \n",
      "               0         1\n",
      "count  5.000000  5.000000\n",
      "mean   0.873866  0.659925\n",
      "std    0.001795  0.004766\n",
      "min    0.871128  0.652694\n",
      "25%    0.873287  0.659017\n",
      "50%    0.874159  0.660567\n",
      "75%    0.874938  0.661522\n",
      "max    0.875819  0.665823\n",
      "answers  (5, 20054)\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "auc_arr = [] \n",
    "import random\n",
    "random.seed(a=10)\n",
    "sedd_arr = random.sample(range(1,10000), 5)\n",
    "# for seed in  [10, 11, 100, 1000, 2025, 1989]:\n",
    "# for seed in  [10, 11, 1989]:\n",
    "for i, seed in enumerate(sedd_arr):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_train, y_train_train, test_size=0.2, random_state=seed, shuffle=True)\n",
    "    #lgb model \n",
    "    lgb_clf, test_pred = lgb_feature(X_train, y_train, X_test, y_test)\n",
    "    train_pred = lgb_clf.predict(X_train)\n",
    "    # train auc, test auc\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc  = roc_auc_score(y_test, test_pred)\n",
    "    print('----------------------------- the %d epoch lgb_model valid auc --------------------- ' % i, train_auc, test_auc)\n",
    "    auc_arr.append((train_auc, test_auc))\n",
    "    #最终输出\n",
    "    final_pred = lgb_clf.predict(X_test_test)\n",
    "    print('final pred ',final_pred)\n",
    "    answers.append(final_pred)\n",
    "print('auc arr \\n', pd.DataFrame(auc_arr, columns=['train auc', 'test_auc']))\n",
    "print('auc describe \\n', pd.DataFrame(auc_arr).describe())\n",
    "print('answers ', np.array(answers).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38f882",
   "metadata": {},
   "source": [
    "# LGB model2  指定种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd800f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.659539\tvalid_1's auc: 0.667848\n",
      "[200]\ttraining's auc: 0.668736\tvalid_1's auc: 0.670083\n",
      "[300]\ttraining's auc: 0.678407\tvalid_1's auc: 0.674028\n",
      "[400]\ttraining's auc: 0.6847\tvalid_1's auc: 0.674625\n",
      "Early stopping, best iteration is:\n",
      "[356]\ttraining's auc: 0.681327\tvalid_1's auc: 0.675241\n",
      "----------------------------- lgb_model valid auc ---------------------  0.6813268150308923 0.6752413555049274\n",
      "final pred  [0.12707165 0.06092715 0.18527327 ... 0.18461119 0.18176325 0.19762524]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.659442\tvalid_1's auc: 0.65961\n",
      "[200]\ttraining's auc: 0.667148\tvalid_1's auc: 0.663661\n",
      "[300]\ttraining's auc: 0.676863\tvalid_1's auc: 0.669536\n",
      "[400]\ttraining's auc: 0.683139\tvalid_1's auc: 0.672334\n",
      "[500]\ttraining's auc: 0.689672\tvalid_1's auc: 0.67365\n",
      "[600]\ttraining's auc: 0.695823\tvalid_1's auc: 0.673289\n",
      "Early stopping, best iteration is:\n",
      "[518]\ttraining's auc: 0.690835\tvalid_1's auc: 0.67421\n",
      "----------------------------- lgb_model valid auc ---------------------  0.6908351633190372 0.6742098399258639\n",
      "final pred  [0.11713188 0.06043029 0.16791809 ... 0.17693878 0.17977502 0.19099719]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.659692\tvalid_1's auc: 0.661894\n",
      "[200]\ttraining's auc: 0.668735\tvalid_1's auc: 0.668041\n",
      "[300]\ttraining's auc: 0.676591\tvalid_1's auc: 0.669761\n",
      "[400]\ttraining's auc: 0.683158\tvalid_1's auc: 0.671468\n",
      "[500]\ttraining's auc: 0.689931\tvalid_1's auc: 0.672114\n",
      "[600]\ttraining's auc: 0.696096\tvalid_1's auc: 0.672546\n",
      "[700]\ttraining's auc: 0.70105\tvalid_1's auc: 0.673137\n",
      "Early stopping, best iteration is:\n",
      "[672]\ttraining's auc: 0.699876\tvalid_1's auc: 0.673703\n",
      "----------------------------- lgb_model valid auc ---------------------  0.6998763637181769 0.6737028629558288\n",
      "final pred  [0.11520068 0.0539027  0.14511383 ... 0.18342646 0.18111751 0.1974058 ]\n",
      "auc arr \n",
      "    train auc  test_auc\n",
      "0   0.681327  0.675241\n",
      "1   0.690835  0.674210\n",
      "2   0.699876  0.673703\n",
      "answers  (3, 20054)\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "auc_arr = [] \n",
    "\n",
    "# for seed in  [10, 11, 100, 1000, 2025, 1989]:\n",
    "for seed in  [10, 11, 1989]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_train, y_train_train, test_size=0.1, random_state=seed, shuffle=True)\n",
    "    #lgb model \n",
    "    lgb_clf, test_pred = lgb_feature2(X_train, y_train, X_test, y_test)\n",
    "    train_pred = lgb_clf.predict(X_train)\n",
    "    # train auc, test auc\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc  = roc_auc_score(y_test, test_pred)\n",
    "    print('----------------------------- lgb_model valid auc --------------------- ', train_auc, test_auc)\n",
    "    auc_arr.append((train_auc, test_auc))\n",
    "    #最终输出\n",
    "    final_pred = lgb_clf.predict(X_test_test)\n",
    "    print('final pred ',final_pred)\n",
    "    answers.append(final_pred)\n",
    "print('auc arr \\n', pd.DataFrame(auc_arr, columns=['train auc', 'test_auc']))\n",
    "print('answers ', np.array(answers).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba0c6e",
   "metadata": {},
   "source": [
    "#  LGB feature2随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fee24f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.661348\tvalid_1's auc: 0.649421\n",
      "[200]\ttraining's auc: 0.670372\tvalid_1's auc: 0.651463\n",
      "[300]\ttraining's auc: 0.677503\tvalid_1's auc: 0.655337\n",
      "[400]\ttraining's auc: 0.684539\tvalid_1's auc: 0.655699\n",
      "[500]\ttraining's auc: 0.690945\tvalid_1's auc: 0.656484\n",
      "[600]\ttraining's auc: 0.696829\tvalid_1's auc: 0.656887\n",
      "[700]\ttraining's auc: 0.702319\tvalid_1's auc: 0.657716\n",
      "[800]\ttraining's auc: 0.707166\tvalid_1's auc: 0.657806\n",
      "[900]\ttraining's auc: 0.71201\tvalid_1's auc: 0.65825\n",
      "[1000]\ttraining's auc: 0.716138\tvalid_1's auc: 0.658093\n",
      "Early stopping, best iteration is:\n",
      "[904]\ttraining's auc: 0.712131\tvalid_1's auc: 0.658296\n",
      "----------------------------- the 0 epoch lgb_model valid auc ---------------------  0.712131483763858 0.658296136553166\n",
      "final pred  [0.09567222 0.05080067 0.15231508 ... 0.17279651 0.17972776 0.18853596]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.660422\tvalid_1's auc: 0.650213\n",
      "[200]\ttraining's auc: 0.669428\tvalid_1's auc: 0.651995\n",
      "[300]\ttraining's auc: 0.676697\tvalid_1's auc: 0.65269\n",
      "[400]\ttraining's auc: 0.683569\tvalid_1's auc: 0.653087\n",
      "[500]\ttraining's auc: 0.689595\tvalid_1's auc: 0.655683\n",
      "[600]\ttraining's auc: 0.696005\tvalid_1's auc: 0.656875\n",
      "[700]\ttraining's auc: 0.701218\tvalid_1's auc: 0.657596\n",
      "[800]\ttraining's auc: 0.706741\tvalid_1's auc: 0.658001\n",
      "Early stopping, best iteration is:\n",
      "[741]\ttraining's auc: 0.703514\tvalid_1's auc: 0.658664\n",
      "----------------------------- the 1 epoch lgb_model valid auc ---------------------  0.7035140494884948 0.6586635426162261\n",
      "final pred  [0.10303683 0.04657848 0.13815647 ... 0.1802483  0.18361704 0.19364959]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.661902\tvalid_1's auc: 0.650063\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's auc: 0.658667\tvalid_1's auc: 0.650896\n",
      "----------------------------- the 2 epoch lgb_model valid auc ---------------------  0.6586665279133002 0.6508956029391025\n",
      "final pred  [0.17377555 0.12408333 0.21143137 ... 0.18221534 0.18257902 0.18720026]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.660374\tvalid_1's auc: 0.655025\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's auc: 0.65556\tvalid_1's auc: 0.657527\n",
      "----------------------------- the 3 epoch lgb_model valid auc ---------------------  0.6555597146488481 0.6575269880611342\n",
      "final pred  [0.17158395 0.13652167 0.19986738 ... 0.18367703 0.18367703 0.18418313]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.660706\tvalid_1's auc: 0.656653\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's auc: 0.65896\tvalid_1's auc: 0.658058\n",
      "----------------------------- the 4 epoch lgb_model valid auc ---------------------  0.6589598098807619 0.6580580133032129\n",
      "final pred  [0.16702259 0.11746042 0.2082888  ... 0.18177553 0.18200557 0.18747131]\n",
      "auc arr \n",
      "    train auc  test_auc\n",
      "0   0.712131  0.658296\n",
      "1   0.703514  0.658664\n",
      "2   0.658667  0.650896\n",
      "3   0.655560  0.657527\n",
      "4   0.658960  0.658058\n",
      "auc describe \n",
      "               0         1\n",
      "count  5.000000  5.000000\n",
      "mean   0.677766  0.656688\n",
      "std    0.027638  0.003264\n",
      "min    0.655560  0.650896\n",
      "25%    0.658667  0.657527\n",
      "50%    0.658960  0.658058\n",
      "75%    0.703514  0.658296\n",
      "max    0.712131  0.658664\n",
      "answers  (5, 20054)\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "auc_arr = [] \n",
    "import random\n",
    "random.seed(a=10)\n",
    "sedd_arr = random.sample(range(1,10000), 5)\n",
    "# for seed in  [10, 11, 100, 1000, 2025, 1989]:\n",
    "# for seed in  [10, 11, 1989]:\n",
    "for i, seed in enumerate(sedd_arr):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_train, y_train_train, test_size=0.1, random_state=seed, shuffle=True)\n",
    "    #lgb model \n",
    "    lgb_clf, test_pred = lgb_feature2(X_train, y_train, X_test, y_test)\n",
    "    train_pred = lgb_clf.predict(X_train)\n",
    "    # train auc, test auc\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc  = roc_auc_score(y_test, test_pred)\n",
    "    print('----------------------------- the %d epoch lgb_model valid auc --------------------- ' % i, train_auc, test_auc)\n",
    "    auc_arr.append((train_auc, test_auc))\n",
    "    #最终输出\n",
    "    final_pred = lgb_clf.predict(X_test_test)\n",
    "    print('final pred ',final_pred)\n",
    "    answers.append(final_pred)\n",
    "print('auc arr \\n', pd.DataFrame(auc_arr, columns=['train auc', 'test_auc']))\n",
    "print('auc describe \\n', pd.DataFrame(auc_arr).describe())\n",
    "print('answers ', np.array(answers).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4e10b807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ans \n",
      "               0         1         2     label     id\n",
      "0      0.127072  0.117132  0.115201  0.119801  53480\n",
      "1      0.060927  0.060430  0.053903  0.058420  53481\n",
      "2      0.185273  0.167918  0.145114  0.166102  53482\n",
      "3      0.242786  0.235228  0.245334  0.241116  53483\n",
      "4      0.117751  0.115344  0.112703  0.115266  53484\n",
      "...         ...       ...       ...       ...    ...\n",
      "20049  0.185612  0.185762  0.188441  0.186605  73529\n",
      "20050  0.118680  0.111380  0.109775  0.113278  73530\n",
      "20051  0.184611  0.176939  0.183426  0.181659  73531\n",
      "20052  0.181763  0.179775  0.181118  0.180885  73532\n",
      "20053  0.197625  0.190997  0.197406  0.195343  73533\n",
      "\n",
      "[20054 rows x 5 columns]\n",
      "df_out \n",
      "           id     label\n",
      "0      53480  0.119801\n",
      "1      53481  0.058420\n",
      "2      53482  0.166102\n",
      "3      53483  0.241116\n",
      "4      53484  0.115266\n",
      "...      ...       ...\n",
      "20049  73529  0.186605\n",
      "20050  73530  0.113278\n",
      "20051  73531  0.181659\n",
      "20052  73532  0.180885\n",
      "20053  73533  0.195343\n",
      "\n",
      "[20054 rows x 2 columns]\n",
      "202508261937_gh_lgb_kfold_v1.csv\n",
      "202508261937_gh_lgb_kfold_v1_answers.txt\n",
      "202508261937_gh_lgb_kfold_v1_full.txt\n",
      "202508261937_gh_lgb_v3.csv\n",
      "202508261937_gh_v1.csv\n",
      "202508261937_gh_v2.csv\n",
      "model_lgb_kfold_v5.3.ipynb\n",
      "model_lgb_v5.2.ipynb\n",
      "model_stacking_v5.0.ipynb\n",
      "model_stacking_v5.1.ipynb\n",
      "model_stacking_v5.ipynb\n",
      "process_v5.ipynb\n",
      "test.dat.202508261937\n",
      "train.dat.202508261937\n"
     ]
    }
   ],
   "source": [
    "#保存结果\n",
    "df_ans = pd.DataFrame(answers).T\n",
    "df_ans['label'] = df_ans.mean(axis = 1)\n",
    "df_ans['id'] = pd.DataFrame({'id':X_test_test.index.values})[['id']]\n",
    "print('df_ans \\n',df_ans)\n",
    "df_out = df_ans[['id','label']]\n",
    "print('df_out \\n',df_out)\n",
    "df_out.to_csv('%s_gh_lgb_kfold_v1.csv' % suffix, encoding='utf-8', index=False, mode='w')\n",
    "df_ans.to_csv('%s_gh_lgb_kfold_v1_answers.txt' % suffix, encoding='utf-8', index=False, mode='w')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe5dd7",
   "metadata": {},
   "source": [
    "# LGB feature2 STRatifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71500de0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.660023\tvalid_1's auc: 0.655701\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's auc: 0.657019\tvalid_1's auc: 0.657069\n",
      "--------------lgb_model valid auc -------------  0.6570193659269206 0.6570693505552871\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.660647\tvalid_1's auc: 0.646978\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.649598\tvalid_1's auc: 0.648634\n",
      "--------------lgb_model valid auc -------------  0.6495979448672948 0.6486344157411879\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.66119\tvalid_1's auc: 0.664896\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's auc: 0.658964\tvalid_1's auc: 0.665616\n",
      "--------------lgb_model valid auc -------------  0.658963964448689 0.6656163427433357\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.660715\tvalid_1's auc: 0.657629\n",
      "[200]\ttraining's auc: 0.668685\tvalid_1's auc: 0.660128\n",
      "[300]\ttraining's auc: 0.675973\tvalid_1's auc: 0.660023\n",
      "[400]\ttraining's auc: 0.683187\tvalid_1's auc: 0.663225\n",
      "[500]\ttraining's auc: 0.690107\tvalid_1's auc: 0.664586\n",
      "Early stopping, best iteration is:\n",
      "[478]\ttraining's auc: 0.688397\tvalid_1's auc: 0.66501\n",
      "--------------lgb_model valid auc -------------  0.6883968863492358 0.6650102260446467\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.660622\tvalid_1's auc: 0.658403\n",
      "[200]\ttraining's auc: 0.669755\tvalid_1's auc: 0.665866\n",
      "[300]\ttraining's auc: 0.678437\tvalid_1's auc: 0.668713\n",
      "[400]\ttraining's auc: 0.684728\tvalid_1's auc: 0.670427\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttraining's auc: 0.684208\tvalid_1's auc: 0.67103\n",
      "--------------lgb_model valid auc -------------  0.6842080561470317 0.6710302197770335\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.662378\tvalid_1's auc: 0.646144\n",
      "[200]\ttraining's auc: 0.669776\tvalid_1's auc: 0.648088\n",
      "[300]\ttraining's auc: 0.677882\tvalid_1's auc: 0.649957\n",
      "[400]\ttraining's auc: 0.684605\tvalid_1's auc: 0.650517\n",
      "[500]\ttraining's auc: 0.691899\tvalid_1's auc: 0.651008\n",
      "Early stopping, best iteration is:\n",
      "[437]\ttraining's auc: 0.687123\tvalid_1's auc: 0.651268\n",
      "--------------lgb_model valid auc -------------  0.6871227898562074 0.6512679854634055\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.662304\tvalid_1's auc: 0.644814\n",
      "[200]\ttraining's auc: 0.670798\tvalid_1's auc: 0.648765\n",
      "[300]\ttraining's auc: 0.678359\tvalid_1's auc: 0.651329\n",
      "[400]\ttraining's auc: 0.683786\tvalid_1's auc: 0.651961\n",
      "[500]\ttraining's auc: 0.690533\tvalid_1's auc: 0.654739\n",
      "[600]\ttraining's auc: 0.697359\tvalid_1's auc: 0.655568\n",
      "[700]\ttraining's auc: 0.703349\tvalid_1's auc: 0.655653\n",
      "[800]\ttraining's auc: 0.708158\tvalid_1's auc: 0.657024\n",
      "[900]\ttraining's auc: 0.712851\tvalid_1's auc: 0.657385\n",
      "Early stopping, best iteration is:\n",
      "[881]\ttraining's auc: 0.712143\tvalid_1's auc: 0.657663\n",
      "--------------lgb_model valid auc -------------  0.712142751577718 0.6576630617452681\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.660324\tvalid_1's auc: 0.651094\n",
      "[200]\ttraining's auc: 0.66939\tvalid_1's auc: 0.656878\n",
      "[300]\ttraining's auc: 0.677509\tvalid_1's auc: 0.659057\n",
      "[400]\ttraining's auc: 0.683959\tvalid_1's auc: 0.661786\n",
      "[500]\ttraining's auc: 0.690263\tvalid_1's auc: 0.664171\n",
      "[600]\ttraining's auc: 0.695919\tvalid_1's auc: 0.66587\n",
      "[700]\ttraining's auc: 0.701227\tvalid_1's auc: 0.667283\n",
      "[800]\ttraining's auc: 0.705848\tvalid_1's auc: 0.668145\n",
      "[900]\ttraining's auc: 0.711217\tvalid_1's auc: 0.669161\n",
      "[1000]\ttraining's auc: 0.716535\tvalid_1's auc: 0.669379\n",
      "Early stopping, best iteration is:\n",
      "[925]\ttraining's auc: 0.712506\tvalid_1's auc: 0.669432\n",
      "--------------lgb_model valid auc -------------  0.7125061989368126 0.6694316536733154\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.662423\tvalid_1's auc: 0.642105\n",
      "[200]\ttraining's auc: 0.67031\tvalid_1's auc: 0.648515\n",
      "[300]\ttraining's auc: 0.677805\tvalid_1's auc: 0.651387\n",
      "[400]\ttraining's auc: 0.684186\tvalid_1's auc: 0.653631\n",
      "[500]\ttraining's auc: 0.689978\tvalid_1's auc: 0.656572\n",
      "[600]\ttraining's auc: 0.695991\tvalid_1's auc: 0.657738\n",
      "[700]\ttraining's auc: 0.702501\tvalid_1's auc: 0.659014\n",
      "[800]\ttraining's auc: 0.707598\tvalid_1's auc: 0.659805\n",
      "[900]\ttraining's auc: 0.712006\tvalid_1's auc: 0.660332\n",
      "Early stopping, best iteration is:\n",
      "[850]\ttraining's auc: 0.710088\tvalid_1's auc: 0.660745\n",
      "--------------lgb_model valid auc -------------  0.7100879043259858 0.6607453727640893\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.658569\tvalid_1's auc: 0.655424\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's auc: 0.654033\tvalid_1's auc: 0.65973\n",
      "--------------lgb_model valid auc -------------  0.6540334658508522 0.6597299591213373\n",
      "auc arr \n",
      "           0         1\n",
      "0  0.657019  0.657069\n",
      "1  0.649598  0.648634\n",
      "2  0.658964  0.665616\n",
      "3  0.688397  0.665010\n",
      "4  0.684208  0.671030\n",
      "5  0.687123  0.651268\n",
      "6  0.712143  0.657663\n",
      "7  0.712506  0.669432\n",
      "8  0.710088  0.660745\n",
      "9  0.654033  0.659730\n",
      "auc arr \n",
      "                0          1\n",
      "count  10.000000  10.000000\n",
      "mean    0.681408   0.660620\n",
      "std     0.025129   0.007330\n",
      "min     0.649598   0.648634\n",
      "25%     0.657506   0.657218\n",
      "50%     0.685665   0.660238\n",
      "75%     0.704665   0.665465\n",
      "max     0.712506   0.671030\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "answers = []\n",
    "auc_arr = [] \n",
    "\n",
    "sk = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=10)\n",
    "y_train_train = pd.DataFrame(y_train_train)\n",
    "for train, test in sk.split(X_train_train, y_train_train):\n",
    "    X_train = X_train_train.iloc[train]\n",
    "    y_train = y_train_train.iloc[train]\n",
    "    X_test  = X_train_train.iloc[test]\n",
    "    y_test  = y_train_train.iloc[test]\n",
    "    lgb_clf, test_pred = lgb_feature2(X_train, y_train, X_test, y_test)\n",
    "    train_pred = lgb_clf.predict(X_train)\n",
    "    # 记录训练集auc, 测试集auc\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    test_auc  = roc_auc_score(y_test, test_pred)\n",
    "    print('--------------lgb_model valid auc ------------- ', train_auc, test_auc)\n",
    "    auc_arr.append((train_auc,test_auc))\n",
    "    #最终输出\n",
    "    final_pred = lgb_clf.predict(X_test_test)\n",
    "    answers.append(final_pred)\n",
    "print('auc arr \\n', pd.DataFrame(auc_arr))\n",
    "print('auc arr describe \\n', pd.DataFrame(auc_arr).describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
