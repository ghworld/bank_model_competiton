{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c284ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.5\n",
      "/d/GH/GitWorkSpace/bank_model_competiton/data/202508271029\n",
      "-rw-r--r-- 1 chenchen 197121 4919052 Aug 27 10:35 test.dat.202508271029\n",
      "-rw-r--r-- 1 chenchen 197121 13451187 Aug 27 10:33 train.dat.202508271029\n",
      "20055 test.dat.202508271029\n",
      "53481 train.dat.202508271029\n",
      "train NF 38\n",
      "test NF 37\n",
      "model_stacking_v6.ipynb\n",
      "process_v6.ipynb\n",
      "test.dat.202508271029\n",
      "train.dat.202508271029\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import os\n",
    "!python --version\n",
    "!pwd\n",
    "suffix=os.path.split(os.getcwd())[-1]\n",
    "!ls -l test.dat.{suffix}\n",
    "!ls -l train.dat.{suffix}\n",
    "!wc -l test.dat.{suffix}\n",
    "!wc -l train.dat.{suffix}\n",
    "!head -n 1 train.dat.202508271029 | awk -F ',' '{print \"train NF\",NF}'\n",
    "!head -n 1 test.dat.202508271029  | awk -F ',' '{print \"test NF\",NF}'\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a7909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.dat.202508271029 test.dat.202508271029 202508271029\n",
      "process time :  2025-08-27 11:00:57\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os\n",
    "import time \n",
    "import matplotlib as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "s\n",
    "model = ''\n",
    "# dummy_fea_str = \"id,title,career,zip_code,residence,syndicated,installment,level\"\n",
    "dummy_fea_str = \"id,level\"\n",
    "dummy_fea = dummy_fea_str.split(',')\n",
    "\n",
    "suffix = os.path.split(os.getcwd())[-1]\n",
    "\n",
    "train_dat_path = \"train.dat.%s\" % suffix \n",
    "test_dat_path = \"test.dat.%s\"  % suffix \n",
    "print(train_dat_path, test_dat_path, suffix)\n",
    "print('process time : ',time.strftime( '%Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f699d",
   "metadata": {},
   "source": [
    "# 定义基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110a63d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_feature(X_train, y_train, X_test, y_test=None):\n",
    "    global model\n",
    "    # 模型参数\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective':'rank:pairwise',\n",
    "              'eval_metric' : 'auc',\n",
    "              'eta': 0.02,\n",
    "              'max_depth': 5,  # 4 3\n",
    "              'colsample_bytree': 0.7,#0.8\n",
    "              'subsample': 0.7,\n",
    "              'min_child_weight': 1,  # 2 3\n",
    "              'seed': 1111,\n",
    "              'silent':1\n",
    "              }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvali = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=800)\n",
    "    predict = model.predict(dvali)\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n",
    "\n",
    "def xgb_feature2(X_train, y_train, X_test, y_test=None):\n",
    "    global model\n",
    "    # 模型参数\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective':'rank:pairwise',\n",
    "              'eval_metric' : 'auc',\n",
    "              'eta': 0.015,\n",
    "              'max_depth': 5,  # 4 3\n",
    "              'colsample_bytree': 0.7,#0.8\n",
    "              'subsample': 0.7,\n",
    "              'min_child_weight': 1,  # 2 3\n",
    "              'seed': 11,\n",
    "              'silent':1\n",
    "              }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvali = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=1200)\n",
    "    predict = model.predict(dvali)\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n",
    "\n",
    "def xgb_feature3(X_train, y_train, X_test, y_test=None):\n",
    "    global model\n",
    "    # 模型参数\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective':'rank:pairwise',\n",
    "              'eval_metric' : 'auc',\n",
    "              'eta': 0.01,\n",
    "              'max_depth': 5,  # 4 3\n",
    "              'colsample_bytree': 0.7,#0.8\n",
    "              'subsample': 0.7,\n",
    "              'min_child_weight': 1,  # 2 3\n",
    "              'seed': 1,\n",
    "              'silent':1\n",
    "              }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvali = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=2000)\n",
    "    predict = model.predict(dvali)\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n",
    "\n",
    "\n",
    "def et_model(X_train, y_train, X_test, y_test=None):\n",
    "    global model\n",
    "    model = ExtraTreesClassifier(max_features = 'log2', n_estimators = 1000 , n_jobs = -1).fit(X_train,y_train)\n",
    "    return model.predict_proba(X_test)[:,1]\n",
    "\n",
    "def gbdt_model(X_train, y_train, X_test, y_test=None):\n",
    "    global model\n",
    "    model = GradientBoostingClassifier(learning_rate = 0.02, max_features = 0.7, n_estimators = 700 , max_depth = 5).fit(X_train,y_train)\n",
    "    predict = model.predict_proba(X_test)[:,1]\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n",
    "\n",
    "def logistic_model(X_train, y_train, X_test, y_test=None):\n",
    "    global model\n",
    "    model = LogisticRegression(penalty = 'l2').fit(X_train,y_train)\n",
    "    return model.predict_proba(X_test)[:,1]\n",
    "\n",
    "def lgb_feature(X_train, y_train, X_test, category_feature, y_test=None):\n",
    "    global model\n",
    "    lgb_train = lgb.Dataset(X_train, y_train,categorical_feature = category_feature)\n",
    "    lgb_test = lgb.Dataset(X_test, categorical_feature = category_feature)\n",
    "#     lgb_test = lgb.Dataset(X_test, categorical_feature = {'sex', 'merriage', 'income', 'qq_bound', 'degree', 'wechat_bound','account_grade','industry'})\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric':'auc',\n",
    "        'num_leaves': 25,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'min_data_in_leaf':5,\n",
    "        'max_bin':200,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "    gbm = lgb.train(params,lgb_train,num_boost_round=2000)\n",
    "    predict = gbm.predict(X_test)\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d1827",
   "metadata": {},
   "source": [
    "## 验证v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379adf36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_df \n",
      "        title_0  title_1  title_10  title_2  title_3  title_4  title_5  \\\n",
      "0            0        0         0        0        0        0        0   \n",
      "1            0        0         0        0        0        0        0   \n",
      "2            0        0         0        0        0        0        0   \n",
      "3            0        0         0        0        0        0        0   \n",
      "4            0        0         0        0        0        0        0   \n",
      "...        ...      ...       ...      ...      ...      ...      ...   \n",
      "53475        0        0         0        1        0        0        0   \n",
      "53476        1        0         0        0        0        0        0   \n",
      "53477        0        0         0        1        0        0        0   \n",
      "53478        1        0         0        0        0        0        0   \n",
      "53479        1        0         0        0        0        0        0   \n",
      "\n",
      "       title_6  title_7  title_8  ...  interest_rate_cut_18  \\\n",
      "0            0        0        0  ...                     0   \n",
      "1            0        0        1  ...                     0   \n",
      "2            0        0        1  ...                     0   \n",
      "3            0        1        0  ...                     0   \n",
      "4            0        0        1  ...                     0   \n",
      "...        ...      ...      ...  ...                   ...   \n",
      "53475        0        0        0  ...                     0   \n",
      "53476        0        0        0  ...                     0   \n",
      "53477        0        0        0  ...                     0   \n",
      "53478        0        0        0  ...                     0   \n",
      "53479        0        0        0  ...                     0   \n",
      "\n",
      "       interest_rate_cut_19  interest_rate_cut_2  interest_rate_cut_3  \\\n",
      "0                         0                    0                    0   \n",
      "1                         0                    0                    0   \n",
      "2                         0                    0                    0   \n",
      "3                         0                    0                    0   \n",
      "4                         0                    0                    0   \n",
      "...                     ...                  ...                  ...   \n",
      "53475                     0                    0                    0   \n",
      "53476                     1                    0                    0   \n",
      "53477                     0                    0                    1   \n",
      "53478                     0                    0                    0   \n",
      "53479                     0                    0                    0   \n",
      "\n",
      "       interest_rate_cut_4  interest_rate_cut_5  interest_rate_cut_6  \\\n",
      "0                        1                    0                    0   \n",
      "1                        0                    1                    0   \n",
      "2                        0                    0                    0   \n",
      "3                        0                    0                    0   \n",
      "4                        0                    0                    1   \n",
      "...                    ...                  ...                  ...   \n",
      "53475                    0                    0                    0   \n",
      "53476                    0                    0                    0   \n",
      "53477                    0                    0                    0   \n",
      "53478                    0                    0                    0   \n",
      "53479                    0                    0                    0   \n",
      "\n",
      "       interest_rate_cut_7  interest_rate_cut_8  interest_rate_cut_9  \n",
      "0                        0                    0                    0  \n",
      "1                        0                    0                    0  \n",
      "2                        0                    0                    0  \n",
      "3                        0                    1                    0  \n",
      "4                        0                    0                    0  \n",
      "...                    ...                  ...                  ...  \n",
      "53475                    0                    0                    0  \n",
      "53476                    0                    0                    0  \n",
      "53477                    0                    0                    0  \n",
      "53478                    0                    0                    0  \n",
      "53479                    0                    0                    1  \n",
      "\n",
      "[53480 rows x 1150 columns]\n",
      "valid sample data :\n",
      "  Index(['loan', 'interest_rate', 'issue_time', 'record_time', 'history_time',\n",
      "       'total_accounts', 'balance_accounts', 'balance_limit', 'balance',\n",
      "       'label',\n",
      "       ...\n",
      "       'interest_rate_cut_18', 'interest_rate_cut_19', 'interest_rate_cut_2',\n",
      "       'interest_rate_cut_3', 'interest_rate_cut_4', 'interest_rate_cut_5',\n",
      "       'interest_rate_cut_6', 'interest_rate_cut_7', 'interest_rate_cut_8',\n",
      "       'interest_rate_cut_9'],\n",
      "      dtype='object', length=1176)\n",
      "valid sample data :\n",
      "          loan  interest_rate  issue_time  record_time  history_time  \\\n",
      "0       7200          10.95  1238631967   1238630622     472006661   \n",
      "1      21300          12.95  1128212052   1161907665     763779041   \n",
      "2      10400          21.05  1249171509   1383958593     727143443   \n",
      "3      33050          16.40  1172882234   1214353935     687660346   \n",
      "4       5200          14.35  1172882384   1240274527     322012875   \n",
      "...      ...            ...         ...          ...           ...   \n",
      "53475   9000          23.55  1172880000   1157587200    1061769600   \n",
      "53476   8000          30.70  1160092800   1138665600    1038268800   \n",
      "53477  10000           9.40  1180310400   1108771200    1087603200   \n",
      "53478   9000          24.40  1176768000   1159660800    1071792000   \n",
      "53479  10000          17.60  1176163200   1159401600    1022976000   \n",
      "\n",
      "       total_accounts  balance_accounts  balance_limit   balance  label  ...  \\\n",
      "0                17.0               9.0        36200.0  13856.00      0  ...   \n",
      "1                17.0               9.0        20400.0  13773.00      1  ...   \n",
      "2                17.0               9.0        10800.0   2023.00      0  ...   \n",
      "3                17.0               9.0        24700.0  21992.00      0  ...   \n",
      "4                17.0               9.0         5100.0   1669.00      1  ...   \n",
      "...               ...               ...            ...       ...    ...  ...   \n",
      "53475            12.0               5.0         3535.0   2595.73      0  ...   \n",
      "53476             5.0               2.0         1965.0   1433.34      0  ...   \n",
      "53477            12.0               5.0         7253.0   3813.79      0  ...   \n",
      "53478             3.0               3.0         2045.0   1006.40      0  ...   \n",
      "53479             7.0               3.0         3213.0   2648.27      0  ...   \n",
      "\n",
      "       interest_rate_cut_18  interest_rate_cut_19  interest_rate_cut_2  \\\n",
      "0                         0                     0                    0   \n",
      "1                         0                     0                    0   \n",
      "2                         0                     0                    0   \n",
      "3                         0                     0                    0   \n",
      "4                         0                     0                    0   \n",
      "...                     ...                   ...                  ...   \n",
      "53475                     0                     0                    0   \n",
      "53476                     0                     1                    0   \n",
      "53477                     0                     0                    0   \n",
      "53478                     0                     0                    0   \n",
      "53479                     0                     0                    0   \n",
      "\n",
      "       interest_rate_cut_3  interest_rate_cut_4  interest_rate_cut_5  \\\n",
      "0                        0                    1                    0   \n",
      "1                        0                    0                    1   \n",
      "2                        0                    0                    0   \n",
      "3                        0                    0                    0   \n",
      "4                        0                    0                    0   \n",
      "...                    ...                  ...                  ...   \n",
      "53475                    0                    0                    0   \n",
      "53476                    0                    0                    0   \n",
      "53477                    1                    0                    0   \n",
      "53478                    0                    0                    0   \n",
      "53479                    0                    0                    0   \n",
      "\n",
      "       interest_rate_cut_6  interest_rate_cut_7  interest_rate_cut_8  \\\n",
      "0                        0                    0                    0   \n",
      "1                        0                    0                    0   \n",
      "2                        0                    0                    0   \n",
      "3                        0                    0                    1   \n",
      "4                        1                    0                    0   \n",
      "...                    ...                  ...                  ...   \n",
      "53475                    0                    0                    0   \n",
      "53476                    0                    0                    0   \n",
      "53477                    0                    0                    0   \n",
      "53478                    0                    0                    0   \n",
      "53479                    0                    0                    0   \n",
      "\n",
      "       interest_rate_cut_9  \n",
      "0                        0  \n",
      "1                        0  \n",
      "2                        0  \n",
      "3                        0  \n",
      "4                        0  \n",
      "...                    ...  \n",
      "53475                    0  \n",
      "53476                    0  \n",
      "53477                    0  \n",
      "53478                    0  \n",
      "53479                    1  \n",
      "\n",
      "[53480 rows x 1176 columns]\n"
     ]
    }
   ],
   "source": [
    "dummy_fea_str = \"title,career,zip_code,residence,syndicated,installment,level,term,interest_rate_cut\"\n",
    "# dummy_fea_str =  \"level\"\n",
    "drop_fea      =  [ 'tx_time_max', 'tx_time_min']\n",
    "dummy_fea     =  dummy_fea_str.split(',')\n",
    "\n",
    "sample_data = pd.read_csv(train_dat_path, engine = 'python');\n",
    "sample_data.drop(drop_fea, axis = 1, inplace=True)\n",
    "sample_data = sample_data.fillna(0)\n",
    "\n",
    "#处理dummy feature\n",
    "df_dummy_str = pd.DataFrame()\n",
    "for fea in dummy_fea :\n",
    "    df_dummy_str[fea] = sample_data[fea].map( lambda x : str(x))\n",
    "dummy_df = pd.get_dummies(df_dummy_str.loc[:,dummy_fea])\n",
    "print('dummy_df \\n',dummy_df)\n",
    "\n",
    "# 合并基础特征与dummy特征\n",
    "sample_data_concat = pd.concat([sample_data, dummy_df], axis=1)\n",
    "sample_data_concat =sample_data_concat.fillna(0)\n",
    "sample_data_concat.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "vaild_sample_data = sample_data_concat.drop(dummy_fea, axis=1)\n",
    "\n",
    "print('valid sample data :\\n ',vaild_sample_data.columns)\n",
    "print('valid sample data :\\n ',vaild_sample_data)\n",
    "\n",
    "sample_data_target = vaild_sample_data['label'].values\n",
    "sample_data_x = vaild_sample_data.drop(['label', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4a213",
   "metadata": {},
   "source": [
    "# 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e72234c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time :  2025-08-27 15:06:04\n",
      "gbdt_model valid auc :  0.6654858255643733\n",
      "process time :  2025-08-27 15:52:45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 模型验证\n",
    "print('process time : ',time.strftime( '%Y-%m-%d %H:%M:%S', time.localtime()))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_data_x, sample_data_target, test_size=0.2, random_state=10, shuffle=True)\n",
    "\n",
    "# # logistic model\n",
    "# predict_result = logistic_model(X_train, y_train, X_test, None)\n",
    "# print('logistic_model valid auc :', roc_auc_score(y_test, predict_result))\n",
    "\n",
    "# gbdt model\n",
    "predict_result1 = gbdt_model(X_train, y_train, X_test, None)\n",
    "print('gbdt_model valid auc : ', roc_auc_score(y_test, predict_result1))\n",
    "\n",
    "# predict_result3 = xgb_feature(X_train, y_train, X_test, None)\n",
    "# print('xgb_feature valid auc : ', roc_auc_score(y_test, predict_result3))\n",
    "\n",
    "# predict_result4 = xgb_feature2(X_train, y_train, X_test, None)\n",
    "# print('xgb_feature2 valid auc : ', roc_auc_score(y_test, predict_result4))\n",
    "\n",
    "# predict_result5 = xgb_feature3(X_train, y_train, X_test, None)\n",
    "# print('xgb_feature3 valid auc : ', roc_auc_score(y_test, predict_result5))\n",
    "\n",
    "print('process time : ',time.strftime( '%Y-%m-%d %H:%M:%S', time.localtime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b4ed7",
   "metadata": {},
   "source": [
    "# 特征重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "922855de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>feat_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>record_time</td>\n",
       "      <td>0.075398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>term</td>\n",
       "      <td>0.069389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>interest_rate_log</td>\n",
       "      <td>0.067587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>interest_rate</td>\n",
       "      <td>0.065451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>issue_time</td>\n",
       "      <td>0.063232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balance</td>\n",
       "      <td>0.044945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>balance_accounts</td>\n",
       "      <td>0.043757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balance_limit</td>\n",
       "      <td>0.042163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>history_time</td>\n",
       "      <td>0.042011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0_amount_avg2</td>\n",
       "      <td>0.040164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zip_code</td>\n",
       "      <td>0.039275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>balance_account_avg</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>total_amount_avg2</td>\n",
       "      <td>0.033953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1_amount_avg2</td>\n",
       "      <td>0.028920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>balance_accounts_ratio</td>\n",
       "      <td>0.027299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>level_hash</td>\n",
       "      <td>0.023911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0_amount_avg</td>\n",
       "      <td>0.023647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>residence</td>\n",
       "      <td>0.019806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1_amount</td>\n",
       "      <td>0.018496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tx_max_min_days</td>\n",
       "      <td>0.016954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tx_count</td>\n",
       "      <td>0.016927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>loan_term_avg</td>\n",
       "      <td>0.016816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>total_amount</td>\n",
       "      <td>0.015656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loan</td>\n",
       "      <td>0.014916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>career</td>\n",
       "      <td>0.014843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_accounts</td>\n",
       "      <td>0.014032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>0.012227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0_amount</td>\n",
       "      <td>0.012016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1_amount_avg</td>\n",
       "      <td>0.011269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>total_amount_avg</td>\n",
       "      <td>0.010233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>interest_rate_cut</td>\n",
       "      <td>0.008075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>level_C3</td>\n",
       "      <td>0.003269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>level_B0</td>\n",
       "      <td>0.002440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>level_E1</td>\n",
       "      <td>0.002325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>level_A3</td>\n",
       "      <td>0.001854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>level_A0</td>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>level_B1</td>\n",
       "      <td>0.001643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>level_D2</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>installment</td>\n",
       "      <td>0.001302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>level_B3</td>\n",
       "      <td>0.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>level_A5</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>level_B2</td>\n",
       "      <td>0.001168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>syndicated</td>\n",
       "      <td>0.001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>level_D4</td>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>level_B5</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>level_C5</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>level_A4</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>level_A2</td>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>level_D5</td>\n",
       "      <td>0.000778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>level_B4</td>\n",
       "      <td>0.000768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>level_D1</td>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>level_E4</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>level_C2</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>level_D3</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>level_C1</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>level_E2</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>level_E3</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>level_C4</td>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>level_A1</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>level_E5</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feat  feat_importances\n",
       "10             record_time          0.075398\n",
       "5                     term          0.069389\n",
       "19       interest_rate_log          0.067587\n",
       "6            interest_rate          0.065451\n",
       "7               issue_time          0.063232\n",
       "15                 balance          0.044945\n",
       "13        balance_accounts          0.043757\n",
       "14           balance_limit          0.042163\n",
       "11            history_time          0.042011\n",
       "32           0_amount_avg2          0.040164\n",
       "2                 zip_code          0.039275\n",
       "16     balance_account_avg          0.035300\n",
       "30       total_amount_avg2          0.033953\n",
       "31           1_amount_avg2          0.028920\n",
       "18  balance_accounts_ratio          0.027299\n",
       "21              level_hash          0.023911\n",
       "29            0_amount_avg          0.023647\n",
       "3                residence          0.019806\n",
       "25                1_amount          0.018496\n",
       "22         tx_max_min_days          0.016954\n",
       "23                tx_count          0.016927\n",
       "17           loan_term_avg          0.016816\n",
       "24            total_amount          0.015656\n",
       "4                     loan          0.014916\n",
       "1                   career          0.014843\n",
       "12          total_accounts          0.014032\n",
       "0                    title          0.012227\n",
       "26                0_amount          0.012016\n",
       "28            1_amount_avg          0.011269\n",
       "27        total_amount_avg          0.010233\n",
       "20       interest_rate_cut          0.008075\n",
       "47                level_C3          0.003269\n",
       "39                level_B0          0.002440\n",
       "55                level_E1          0.002325\n",
       "36                level_A3          0.001854\n",
       "33                level_A0          0.001794\n",
       "40                level_B1          0.001643\n",
       "51                level_D2          0.001618\n",
       "9              installment          0.001302\n",
       "42                level_B3          0.001282\n",
       "38                level_A5          0.001277\n",
       "41                level_B2          0.001168\n",
       "8               syndicated          0.001085\n",
       "53                level_D4          0.001058\n",
       "44                level_B5          0.000944\n",
       "49                level_C5          0.000943\n",
       "37                level_A4          0.000900\n",
       "35                level_A2          0.000812\n",
       "54                level_D5          0.000778\n",
       "43                level_B4          0.000768\n",
       "50                level_D1          0.000745\n",
       "58                level_E4          0.000621\n",
       "46                level_C2          0.000566\n",
       "52                level_D3          0.000497\n",
       "45                level_C1          0.000356\n",
       "56                level_E2          0.000353\n",
       "57                level_E3          0.000334\n",
       "48                level_C4          0.000281\n",
       "34                level_A1          0.000279\n",
       "59                level_E5          0.000041"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fea_importance = pd.DataFrame({'feat': model.feature_names_in_ , 'feat_importances' : model.feature_importances_ })\n",
    "pd.set_option('display.max_rows', 100)\n",
    "df_fea_importance.sort_values(by='feat_importances',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f94e8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(x='feat_importances', y='feat', data=df_fea_importance)\n",
    "# df_fea_importance.plot(kind='bar')\n",
    "# plt.set_title('Feature Importance')\n",
    "# plt.xlabel('Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1091427e",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff7c4785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       title  career  zip_code  residence   loan  term  interest_rate  \\\n",
      "0          9     0.0    221373          1   7200    36          10.95   \n",
      "1          8    10.0    311681          0  21300    36          12.95   \n",
      "2          8     7.0    271562          1  10400    60          21.05   \n",
      "3          7     2.0    522083          0  33050    36          16.40   \n",
      "4          8     3.0    101026          1   5200    36          14.35   \n",
      "...      ...     ...       ...        ...    ...   ...            ...   \n",
      "73529      0     8.0    601107          1  10000    12          18.85   \n",
      "73530      0    10.0    601102          1  10000    12          29.30   \n",
      "73531      0     4.0    601408          1  11000    12          24.75   \n",
      "73532      0     3.0    601904          1   8000    12          22.00   \n",
      "73533      2     1.0    601809          1   7000    12          14.95   \n",
      "\n",
      "       issue_time  syndicated  installment  ...  level_D1  level_D2  level_D3  \\\n",
      "0      1238631967           0            1  ...         0         0         0   \n",
      "1      1128212052           0            0  ...         0         0         0   \n",
      "2      1249171509           0            0  ...         0         0         0   \n",
      "3      1172882234           0            1  ...         0         0         0   \n",
      "4      1172882384           0            0  ...         0         0         0   \n",
      "...           ...         ...          ...  ...       ...       ...       ...   \n",
      "73529  1130976000           0            0  ...         0         0         0   \n",
      "73530  1156204800           0            0  ...         0         0         0   \n",
      "73531  1144108800           0            0  ...         0         0         0   \n",
      "73532  1163808000           0            0  ...         0         0         0   \n",
      "73533  1188777600           0            0  ...         0         0         0   \n",
      "\n",
      "       level_D4  level_D5  level_E1  level_E2  level_E3  level_E4  level_E5  \n",
      "0             0         0         0         0         0         0         0  \n",
      "1             0         0         0         0         0         0         0  \n",
      "2             0         0         0         0         0         0         0  \n",
      "3             0         0         0         0         0         0         0  \n",
      "4             0         0         0         0         0         0         0  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "73529         0         0         0         0         0         0         0  \n",
      "73530         0         0         0         0         0         0         0  \n",
      "73531         0         0         0         0         0         0         0  \n",
      "73532         0         0         0         0         0         0         0  \n",
      "73533         0         0         0         0         0         0         0  \n",
      "\n",
      "[73534 rows x 61 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20054"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_dat_path, engine = 'python');\n",
    "train_data = train_data.fillna(0)\n",
    "\n",
    "test_data = pd.read_csv(test_dat_path, engine = 'python');\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "train_test_data = pd.concat([train_data, test_data], axis=0, ignore_index = True)\n",
    "train_test_data.drop([ 'tx_time_max', 'tx_time_min'], axis = 1, inplace=True)\n",
    "\n",
    "train_test_data = train_test_data.fillna(0)\n",
    "train_test_data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "dummy_df = pd.get_dummies(train_test_data.loc[:,dummy_fea])\n",
    "train_test_data = pd.concat([train_test_data, dummy_df], axis=1)\n",
    "train_test_data = train_test_data.drop(dummy_fea, axis=1)\n",
    "print(train_test_data)\n",
    "\n",
    "train_train = train_test_data.iloc[:train_data.shape[0],:]\n",
    "test_test = train_test_data.iloc[train_data.shape[0]:,:]\n",
    "\n",
    "y_train = train_train['label'].values\n",
    "X_train = train_train.drop(['label'],axis=1)\n",
    "X_test = test_test.drop(['label'],axis=1)\n",
    "\n",
    "# gbdt model\n",
    "predict_result = gbdt_model(X_train, y_train, X_test, None)\n",
    "# print('gbdt_model valid auc : ', roc_auc_score(y_test, predict_result))\n",
    "\n",
    "len(predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8ea84be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>career</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>residence</th>\n",
       "      <th>loan</th>\n",
       "      <th>term</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>issue_time</th>\n",
       "      <th>syndicated</th>\n",
       "      <th>...</th>\n",
       "      <th>level_D1</th>\n",
       "      <th>level_D2</th>\n",
       "      <th>level_D3</th>\n",
       "      <th>level_D4</th>\n",
       "      <th>level_D5</th>\n",
       "      <th>level_E1</th>\n",
       "      <th>level_E2</th>\n",
       "      <th>level_E3</th>\n",
       "      <th>level_E4</th>\n",
       "      <th>level_E5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53480</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512068</td>\n",
       "      <td>0</td>\n",
       "      <td>5950</td>\n",
       "      <td>36</td>\n",
       "      <td>14.10</td>\n",
       "      <td>1054600001</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53481</td>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>401852</td>\n",
       "      <td>2</td>\n",
       "      <td>15350</td>\n",
       "      <td>36</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1172880047</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53482</td>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>321693</td>\n",
       "      <td>0</td>\n",
       "      <td>11050</td>\n",
       "      <td>36</td>\n",
       "      <td>13.65</td>\n",
       "      <td>1238631003</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53483</td>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>231397</td>\n",
       "      <td>0</td>\n",
       "      <td>15350</td>\n",
       "      <td>36</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1136161107</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53484</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>171193</td>\n",
       "      <td>0</td>\n",
       "      <td>7800</td>\n",
       "      <td>36</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1214960354</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20049</th>\n",
       "      <td>73529</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>601107</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>12</td>\n",
       "      <td>18.85</td>\n",
       "      <td>1130976000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20050</th>\n",
       "      <td>73530</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>601102</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>12</td>\n",
       "      <td>29.30</td>\n",
       "      <td>1156204800</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20051</th>\n",
       "      <td>73531</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>601408</td>\n",
       "      <td>1</td>\n",
       "      <td>11000</td>\n",
       "      <td>12</td>\n",
       "      <td>24.75</td>\n",
       "      <td>1144108800</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20052</th>\n",
       "      <td>73532</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>601904</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>12</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1163808000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20053</th>\n",
       "      <td>73533</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>601809</td>\n",
       "      <td>1</td>\n",
       "      <td>7000</td>\n",
       "      <td>12</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1188777600</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20054 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  title  career  zip_code  residence   loan  term  interest_rate  \\\n",
       "0      53480     10     5.0    512068          0   5950    36          14.10   \n",
       "1      53481      8    10.0    401852          2  15350    36           5.25   \n",
       "2      53482      8    10.0    321693          0  11050    36          13.65   \n",
       "3      53483      8     7.0    231397          0  15350    36          14.20   \n",
       "4      53484      7     7.0    171193          0   7800    36          10.00   \n",
       "...      ...    ...     ...       ...        ...    ...   ...            ...   \n",
       "20049  73529      0     8.0    601107          1  10000    12          18.85   \n",
       "20050  73530      0    10.0    601102          1  10000    12          29.30   \n",
       "20051  73531      0     4.0    601408          1  11000    12          24.75   \n",
       "20052  73532      0     3.0    601904          1   8000    12          22.00   \n",
       "20053  73533      2     1.0    601809          1   7000    12          14.95   \n",
       "\n",
       "       issue_time  syndicated  ...  level_D1  level_D2  level_D3  level_D4  \\\n",
       "0      1054600001           0  ...         0         0         0         0   \n",
       "1      1172880047           0  ...         0         0         0         0   \n",
       "2      1238631003           0  ...         0         0         0         0   \n",
       "3      1136161107           0  ...         0         0         0         0   \n",
       "4      1214960354           0  ...         0         0         0         0   \n",
       "...           ...         ...  ...       ...       ...       ...       ...   \n",
       "20049  1130976000           0  ...         0         0         0         0   \n",
       "20050  1156204800           0  ...         0         0         0         0   \n",
       "20051  1144108800           0  ...         0         0         0         0   \n",
       "20052  1163808000           0  ...         0         0         0         0   \n",
       "20053  1188777600           0  ...         0         0         0         0   \n",
       "\n",
       "       level_D5  level_E1  level_E2  level_E3  level_E4  level_E5  \n",
       "0             0         0         0         0         0         0  \n",
       "1             0         0         0         0         0         0  \n",
       "2             0         0         0         0         0         0  \n",
       "3             0         0         0         0         0         0  \n",
       "4             0         0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "20049         0         0         0         0         0         0  \n",
       "20050         0         0         0         0         0         0  \n",
       "20051         0         0         0         0         0         0  \n",
       "20052         0         0         0         0         0         0  \n",
       "20053         0         0         0         0         0         0  \n",
       "\n",
       "[20054 rows x 61 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test)\n",
    "X_test.reset_index(inplace=True)\n",
    "X_test.rename(columns={'index':'id'}, inplace=True)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5f148a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20049</th>\n",
       "      <td>73529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20050</th>\n",
       "      <td>73530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20051</th>\n",
       "      <td>73531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20052</th>\n",
       "      <td>73532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20053</th>\n",
       "      <td>73533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20054 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id\n",
       "0      53480\n",
       "1      53481\n",
       "2      53482\n",
       "3      53483\n",
       "4      53484\n",
       "...      ...\n",
       "20049  73529\n",
       "20050  73530\n",
       "20051  73531\n",
       "20052  73532\n",
       "20053  73533\n",
       "\n",
       "[20054 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_id = X_test[['id']].iloc[:,[0]]\n",
    "df_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbf78532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20054, 1)\n",
      "202508261937_gh_v1.csv\n",
      "202508261937_gh_v2.csv\n",
      "model_stacking_v5.ipynb\n",
      "process_v5.ipynb\n",
      "test.dat.202508261937\n",
      "train.dat.202508261937\n"
     ]
    }
   ],
   "source": [
    "print(df_test_id.shape)\n",
    "df_test_id['label'] = predict_result\n",
    "minmin = min(df_test_id['label'])\n",
    "maxmax = max(df_test_id['label'])\n",
    "df_test_id['label'] = df_test_id['label'].map(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "df_test_id[['id','label']].to_csv('%s_gh_v2.csv' % suffix, encoding='utf-8', index=False, mode='w')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9358be",
   "metadata": {},
   "source": [
    "## 验证v2  :  LGB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c460bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb sample data\n",
      "           id  title  career  zip_code  residence   loan  term  interest_rate  \\\n",
      "0          0      9       0       271          1   7200    36          10.95   \n",
      "1          1      8      10       508          0  21300    36          12.95   \n",
      "2          2      8       7       424          1  10400    60          21.05   \n",
      "3          3      7       2       766          0  33050    36          16.40   \n",
      "4          4      8       3        25          1   5200    36          14.35   \n",
      "...      ...    ...     ...       ...        ...    ...   ...            ...   \n",
      "53475  53475      2       2      1057          1   9000    12          23.55   \n",
      "53476  53476      0      10       916          1   8000    12          30.70   \n",
      "53477  53477      2      10      1043          1  10000    12           9.40   \n",
      "53478  53478      0      10       960          2   9000    12          24.40   \n",
      "53479  53479      0      10       976          1  10000    12          17.60   \n",
      "\n",
      "       issue_time  syndicated  ...  tx_count   total_amount      1_amount  \\\n",
      "0      1238631967           0  ...      48.0   71787.000000  12079.500000   \n",
      "1      1128212052           0  ...       0.0       0.000000      0.000000   \n",
      "2      1249171509           0  ...      48.0   22406.100000  15883.720000   \n",
      "3      1172882234           0  ...       0.0       0.000000      0.000000   \n",
      "4      1172882384           0  ...      93.0   51163.000000  30823.100000   \n",
      "...           ...         ...  ...       ...            ...           ...   \n",
      "53475  1172880000           0  ...       0.0       0.000000      0.000000   \n",
      "53476  1160092800           0  ...       0.0       0.000000      0.000000   \n",
      "53477  1180310400           0  ...     251.0  113461.244335  69300.836223   \n",
      "53478  1176768000           0  ...       0.0       0.000000      0.000000   \n",
      "53479  1176163200           0  ...       0.0       0.000000      0.000000   \n",
      "\n",
      "           0_amount  total_amount_avg  1_amount_avg  0_amount_avg  \\\n",
      "0      59707.500000        440.411043     74.107362    366.303681   \n",
      "1          0.000000          0.000000      0.000000      0.000000   \n",
      "2       6522.380000        124.478333     88.242889     36.235444   \n",
      "3          0.000000          0.000000      0.000000      0.000000   \n",
      "4      20339.900000        302.739645    182.385207    120.354438   \n",
      "...             ...               ...           ...           ...   \n",
      "53475      0.000000          0.000000      0.000000      0.000000   \n",
      "53476      0.000000          0.000000      0.000000      0.000000   \n",
      "53477  44160.408112        630.340246    385.004646    245.335601   \n",
      "53478      0.000000          0.000000      0.000000      0.000000   \n",
      "53479      0.000000          0.000000      0.000000      0.000000   \n",
      "\n",
      "       total_amount_avg2  1_amount_avg2  0_amount_avg2  \n",
      "0            1495.562500     251.656250    1243.906250  \n",
      "1               0.000000       0.000000       0.000000  \n",
      "2             466.793750     330.910833     135.882917  \n",
      "3               0.000000       0.000000       0.000000  \n",
      "4             550.139785     331.431183     218.708602  \n",
      "...                  ...            ...            ...  \n",
      "53475           0.000000       0.000000       0.000000  \n",
      "53476           0.000000       0.000000       0.000000  \n",
      "53477         452.036830     276.098949     175.937881  \n",
      "53478           0.000000       0.000000       0.000000  \n",
      "53479           0.000000       0.000000       0.000000  \n",
      "\n",
      "[53480 rows x 35 columns]\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "lgb_model valid auc :  0.631823495441353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dummy_fea_str = \"level\"\n",
    "dummy_fea = dummy_fea_str.split(',')\n",
    "drop_fea = ['tx_time_max', 'tx_time_min']\n",
    "category_feature_str = \"id,title,career,zip_code,residence,syndicated,installment,level,interest_rate_cut\"\n",
    "category_feature = category_feature_str.split(',')\n",
    "\n",
    "sample_data_0 = pd.read_csv(train_dat_path, engine = 'python');\n",
    "sample_data.drop(drop_fea, axis = 1, inplace=True)\n",
    "sample_data = sample_data_0.fillna(0)\n",
    "sample_data_concat.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "#1. lgb feature\n",
    "#处理dummy变量\n",
    "for _fea in dummy_fea:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(sample_data[_fea].tolist())\n",
    "    tmp = le.transform(sample_data[_fea].tolist())\n",
    "    sample_data[_fea] = tmp\n",
    "print('lgb sample data\\n', sample_data)\n",
    "sample_data_target = sample_data['label'].values\n",
    "sample_data_x      = sample_data.drop(['label', 'id'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_data_x, sample_data_target, test_size=0.2, random_state=None, shuffle=True)\n",
    "\n",
    "predict_result = lgb_feature(X_train, y_train, X_test, dummy_fea, None)\n",
    "print('lgb_model valid auc : ', roc_auc_score(y_test, predict_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9eb17",
   "metadata": {},
   "source": [
    "# 验证v3 : stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88571cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb sample data\n",
      "           id  title  career  zip_code  residence   loan  term  interest_rate  \\\n",
      "0          0      9       0       271          1   7200    36          10.95   \n",
      "1          1      8      10       508          0  21300    36          12.95   \n",
      "2          2      8       7       424          1  10400    60          21.05   \n",
      "3          3      7       2       766          0  33050    36          16.40   \n",
      "4          4      8       3        25          1   5200    36          14.35   \n",
      "...      ...    ...     ...       ...        ...    ...   ...            ...   \n",
      "53475  53475      2       2      1057          1   9000    12          23.55   \n",
      "53476  53476      0      10       916          1   8000    12          30.70   \n",
      "53477  53477      2      10      1043          1  10000    12           9.40   \n",
      "53478  53478      0      10       960          2   9000    12          24.40   \n",
      "53479  53479      0      10       976          1  10000    12          17.60   \n",
      "\n",
      "       issue_time  syndicated  ...  level  label      0      1              2  \\\n",
      "0      1238631967           0  ...      4      0  163.0   48.0   71787.000000   \n",
      "1      1128212052           0  ...      6      1    0.0    0.0       0.000000   \n",
      "2      1249171509           0  ...     10      0  180.0   48.0   22406.100000   \n",
      "3      1172882234           0  ...      9      0    0.0    0.0       0.000000   \n",
      "4      1172882384           0  ...      8      1  169.0   93.0   51163.000000   \n",
      "...           ...         ...  ...    ...    ...    ...    ...            ...   \n",
      "53475  1172880000           0  ...      4      0    0.0    0.0       0.000000   \n",
      "53476  1160092800           0  ...      8      0    0.0    0.0       0.000000   \n",
      "53477  1180310400           0  ...      8      0  180.0  251.0  113461.244335   \n",
      "53478  1176768000           0  ...      2      0    0.0    0.0       0.000000   \n",
      "53479  1176163200           0  ...      0      0    0.0    0.0       0.000000   \n",
      "\n",
      "                  3             4         5         6         7  \n",
      "0      12079.500000  59707.500000  437.7256   73.6555  364.0701  \n",
      "1          0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "2      15883.720000   6522.380000  123.7906   87.7554   36.0352  \n",
      "3          0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "4      30823.100000  20339.900000  300.9588  181.3124  119.6465  \n",
      "...             ...           ...       ...       ...       ...  \n",
      "53475      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "53476      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "53477  69300.836223  44160.408112  626.8577  382.8775  243.9802  \n",
      "53478      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "53479      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "\n",
      "[53480 rows x 27 columns]\n",
      "xgb dummy_df\n",
      "            id  title  career  zip_code  residence  syndicated  installment  \\\n",
      "0          0      9     0.0    221373          1           0            1   \n",
      "1          1      8    10.0    311681          0           0            0   \n",
      "2          2      8     7.0    271562          1           0            0   \n",
      "3          3      7     2.0    522083          0           0            1   \n",
      "4          4      8     3.0    101026          1           0            0   \n",
      "...      ...    ...     ...       ...        ...         ...          ...   \n",
      "53475  53475      2     2.0    603000          1           0            0   \n",
      "53476  53476      0    10.0    601702          1           0            0   \n",
      "53477  53477      2    10.0    602808          1           0            0   \n",
      "53478  53478      0    10.0    602102          2           0            0   \n",
      "53479  53479      0    10.0    602207          1           0            0   \n",
      "\n",
      "       level_A0  level_A1  level_A2  ...  level_D1  level_D2  level_D3  \\\n",
      "0             0         0         0  ...         0         0         0   \n",
      "1             0         0         0  ...         0         0         0   \n",
      "2             0         0         0  ...         0         0         0   \n",
      "3             0         0         0  ...         0         0         0   \n",
      "4             0         0         0  ...         0         0         0   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "53475         0         0         0  ...         0         0         0   \n",
      "53476         0         0         0  ...         0         0         0   \n",
      "53477         0         0         0  ...         0         0         0   \n",
      "53478         0         0         1  ...         0         0         0   \n",
      "53479         1         0         0  ...         0         0         0   \n",
      "\n",
      "       level_D4  level_D5  level_E1  level_E2  level_E3  level_E4  level_E5  \n",
      "0             0         0         0         0         0         0         0  \n",
      "1             0         0         0         0         0         0         0  \n",
      "2             0         0         0         0         0         0         0  \n",
      "3             0         0         0         0         0         0         0  \n",
      "4             0         0         0         0         0         0         0  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "53475         0         0         0         0         0         0         0  \n",
      "53476         0         0         0         0         0         0         0  \n",
      "53477         0         0         0         0         0         0         0  \n",
      "53478         0         0         0         0         0         0         0  \n",
      "53479         0         0         0         0         0         0         0  \n",
      "\n",
      "[53480 rows x 34 columns]\n",
      "xgb valid sample data Index(['loan', 'term', 'interest_rate', 'issue_time', 'record_time',\n",
      "       'history_time', 'total_accounts', 'balance_accounts', 'balance_limit',\n",
      "       'balance', 'label', '0', '1', '2', '3', '4', '5', '6', '7', 'level_A0',\n",
      "       'level_A1', 'level_A2', 'level_A3', 'level_A4', 'level_A5', 'level_B0',\n",
      "       'level_B1', 'level_B2', 'level_B3', 'level_B4', 'level_B5', 'level_C1',\n",
      "       'level_C2', 'level_C3', 'level_C4', 'level_C5', 'level_D1', 'level_D2',\n",
      "       'level_D3', 'level_D4', 'level_D5', 'level_E1', 'level_E2', 'level_E3',\n",
      "       'level_E4', 'level_E5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dummy_fea_str = \"id,title,career,zip_code,residence,syndicated,installment,level\"\n",
    "dummy_fea = dummy_fea_str.split(',')\n",
    "\n",
    "sample_data_0 = pd.read_csv(train_dat_path, engine = 'python');\n",
    "sample_data = sample_data_0.fillna(0)\n",
    "\n",
    "#1. lgb feature\n",
    "#处理dummy变量\n",
    "for _fea in dummy_fea:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(sample_data[_fea].tolist())\n",
    "    tmp = le.transform(sample_data[_fea].tolist())\n",
    "    sample_data[_fea] = tmp\n",
    "print('lgb sample data\\n', sample_data)\n",
    "sample_data_target = sample_data['label'].values\n",
    "sample_data_x      = sample_data.drop(['label'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_data_x, sample_data_target, test_size=0.2, random_state=None, shuffle=True)\n",
    "lgb_dataset = Dataset(X_train=X_train, y_train=y_train, X_test = X_test, y_test= None, use_cache=False)\n",
    "\n",
    "\n",
    "##2. xgb feature\n",
    "sample_data = sample_data_0.fillna(0)\n",
    "dummy_df = pd.get_dummies(sample_data.loc[:,dummy_fea])\n",
    "print('xgb dummy_df\\n ',dummy_df)\n",
    "sample_data_concat = pd.concat([sample_data, dummy_df], axis=1)\n",
    "sample_data_concat = sample_data_concat.fillna(0)\n",
    "vaild_sample_data = sample_data_concat.drop(dummy_fea, axis=1)\n",
    "print('xgb valid sample data', vaild_sample_data.columns)\n",
    "\n",
    "sample_data_target = vaild_sample_data['label'].values\n",
    "sample_data_x = vaild_sample_data.drop(['label'],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_data_x, sample_data_target, test_size=0.2, random_state=None, shuffle=True)\n",
    "xgb_dataset = Dataset(X_train=X_train, y_train=y_train, X_test = X_test, y_test= None, use_cache=False)\n",
    "\n",
    "model_xgb  = Regressor(dataset=xgb_dataset, estimator=xgb_feature,name='xgb',use_cache=False)\n",
    "model_xgb2 = Regressor(dataset=xgb_dataset, estimator=xgb_feature2,name='xgb2',use_cache=False)\n",
    "model_xgb3 = Regressor(dataset=xgb_dataset, estimator=xgb_feature3,name='xgb3',use_cache=False)\n",
    "# model_lgb = Regressor(dataset=lgb_dataset, estimator=lgb_feature,name='lgb',use_cache=False)\n",
    "model_gbdt = Regressor(dataset=xgb_dataset, estimator=gbdt_model,name='gbdt',use_cache=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d2d8d5",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a82d5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:58:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:58:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:58:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:59:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:59:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:00:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:00:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:01:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:01:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:02:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:03:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:03:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:04:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:05:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:06:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:08:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:09:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:10:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "ModelsPipeline(model_xgb, model_xgb2, model_xgb3, model_gbdt) valid auc 0.6502413981951595\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = ModelsPipeline(model_xgb, model_xgb2, model_xgb3, model_gbdt)\n",
    "stack_ds = pipeline.stack(k=5, seed=111, add_diff=False, full_test=True)\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LinearRegression, parameters={'fit_intercept': False})\n",
    "predict_result = stacker.predict()\n",
    "\n",
    "print('ModelsPipeline(model_xgb, model_xgb2, model_xgb3, model_gbdt) valid auc', roc_auc_score(y_test, predict_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a661b",
   "metadata": {},
   "source": [
    "## lgb feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.dat',engine = 'python');\n",
    "train_data = train_data.fillna(0)\n",
    "\n",
    "test_data = pd.read_csv('test.dat',engine = 'python');\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "train_test_data = pd.concat([train_data, test_data],axis=0,ignore_index = True)\n",
    "train_test_data = train_test_data.fillna(0)\n",
    "\n",
    "train_data = train_test_data.iloc[:train_data.shape[0],:]\n",
    "test_data = train_test_data.iloc[train_data.shape[0]:,:]\n",
    "\n",
    "#处理dummy变量\n",
    "for _fea in dummy_fea:\n",
    "    print(_fea)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data[_fea].tolist() + test_data[_fea].tolist())\n",
    "    tmp = le.transform(train_data[_fea].tolist() + test_data[_fea].tolist())\n",
    "    train_data[_fea] = tmp[:train_data.shape[0]]\n",
    "    test_data[_fea]  = tmp[train_data.shape[0]:]\n",
    "    \n",
    "train_x = train_data.drop(['label'],axis=1)\n",
    "test_x = test_data.drop(['label'],axis=1)\n",
    "lgb_dataset = Dataset(train_x, train_data['label'], test_x, use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fe88f",
   "metadata": {},
   "source": [
    "## xgb feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.dat',engine = 'python');\n",
    "train_data = train_data.fillna(0)\n",
    "\n",
    "test_data = pd.read_csv('test.dat',engine = 'python');\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "train_test_data = pd.concat([train_data, test_data], axis=0, ignore_index = True)\n",
    "train_test_data = train_test_data.fillna(0)\n",
    "\n",
    "dummy_df = pd.get_dummies(train_test_data.loc[:,dummy_fea])\n",
    "train_test_data = pd.concat([train_test_data, dummy_df],axis=1)\n",
    "train_test_data = train_test_data.drop(dummy_fea, axis=1)\n",
    "\n",
    "train_train = train_test_data.iloc[:train_data.shape[0],:]\n",
    "test_test = train_test_data.iloc[train_data.shape[0]:,:]\n",
    "\n",
    "train_train_x = train_train.drop(['label'],axis=1)\n",
    "test_test_x = test_test.drop(['label'],axis=1)\n",
    "\n",
    "xgb_dataset = Dataset(X_train=train_train_x, y_train=train_train['label'], X_test = test_test_x, y_test= None, use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6906bb",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = Regressor(dataset=xgb_dataset, estimator=xgb_feature,name='xgb',use_cache=False)\n",
    "model_xgb2 = Regressor(dataset=xgb_dataset, estimator=xgb_feature2,name='xgb2',use_cache=False)\n",
    "model_xgb3 = Regressor(dataset=xgb_dataset, estimator=xgb_feature3,name='xgb3',use_cache=False)\n",
    "model_lgb = Regressor(dataset=lgb_dataset, estimator=lgb_feature,name='lgb',use_cache=False)\n",
    "model_gbdt = Regressor(dataset=xgb_dataset, estimator=gbdt_model,name='gbdt',use_cache=False)\n",
    "pipeline = ModelsPipeline(model_xgb, model_xgb2, model_xgb3, model_gbdt)\n",
    "stack_ds = pipeline.stack(k=5, seed=111, add_diff=False, full_test=True)\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LinearRegression,parameters={'fit_intercept': False})\n",
    "predict_result = stacker.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.read_csv('testaa.csv')\n",
    "ans['PROB'] = predict_result\n",
    "minmin = min(ans['PROB']),\n",
    "maxmax = max(ans['PROB'])\n",
    "ans['PROB'] = ans['PROB'].map(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "ans['PROB'] = ans['PROB'].map(lambda x:'%.4f' % x)\n",
    "ans.to_csv('./ans_stacking.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
