{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c284ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.5\n",
      "/d/GH/GitWorkSpace/bank_model_competiton\n",
      "0825_lgb_base_cv_v0.1.csv\n",
      "0825_lgb_base_cv_v0.2.csv\n",
      "0825_lgb_base_cv_v0.3.csv\n",
      "data_eda.py\n",
      "model.ipynb\n",
      "process.ipynb\n",
      "process.py\n",
      "test.dat\n",
      "testaa\n",
      "testaa.csv\n",
      "testaa_bank_statement.csv\n",
      "testaa_submit_example.csv\n",
      "train\n",
      "train.csv\n",
      "train.dat\n",
      "train_bank_statement.csv\n",
      "~$姣旇禌瀛楁�佃В閲�.xlsx\n",
      "鍒濊禌A姒滄暟鎹�闆�\n",
      "鏁版嵁鎺㈡煡.ipynb\n",
      "姣旇禌瀛楁�佃В閲�.xlsx\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "!python --version\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a7909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "dummy_fea_str = \"id,title,career,zip_code,residence,syndicated,installment,level\"\n",
    "dummy_fea = dummy_fea_str.split(',')\n",
    "\n",
    "train_dat_path = \"train.dat\"\n",
    "test_dat_path = \"test.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "110a63d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xgb_feature(X_train, y_train, X_test, y_test=None):\n",
    "    # 模型参数\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective':'rank:pairwise',\n",
    "              'eval_metric' : 'auc',\n",
    "              'eta': 0.02,\n",
    "              'max_depth': 5,  # 4 3\n",
    "              'colsample_bytree': 0.7,#0.8\n",
    "              'subsample': 0.7,\n",
    "              'min_child_weight': 1,  # 2 3\n",
    "              'seed': 1111,\n",
    "              'silent':1\n",
    "              }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvali = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=800)\n",
    "    predict = model.predict(dvali)\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n",
    "\n",
    "def xgb_feature2(X_train, y_train, X_test, y_test=None):\n",
    "    # 模型参数\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective':'rank:pairwise',\n",
    "              'eval_metric' : 'auc',\n",
    "              'eta': 0.015,\n",
    "              'max_depth': 5,  # 4 3\n",
    "              'colsample_bytree': 0.7,#0.8\n",
    "              'subsample': 0.7,\n",
    "              'min_child_weight': 1,  # 2 3\n",
    "              'seed': 11,\n",
    "              'silent':1\n",
    "              }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvali = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=1200)\n",
    "    predict = model.predict(dvali)\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n",
    "\n",
    "def xgb_feature3(X_train, y_train, X_test, y_test=None):\n",
    "    # 模型参数\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective':'rank:pairwise',\n",
    "              'eval_metric' : 'auc',\n",
    "              'eta': 0.01,\n",
    "              'max_depth': 5,  # 4 3\n",
    "              'colsample_bytree': 0.7,#0.8\n",
    "              'subsample': 0.7,\n",
    "              'min_child_weight': 1,  # 2 3\n",
    "              'seed': 1,\n",
    "              'silent':1\n",
    "              }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvali = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=2000)\n",
    "    predict = model.predict(dvali)\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n",
    "\n",
    "\n",
    "def et_model(X_train, y_train, X_test, y_test=None):\n",
    "    model = ExtraTreesClassifier(max_features = 'log2', n_estimators = 1000 , n_jobs = -1).fit(X_train,y_train)\n",
    "    return model.predict_proba(X_test)[:,1]\n",
    "\n",
    "def gbdt_model(X_train, y_train, X_test, y_test=None):\n",
    "    model = GradientBoostingClassifier(learning_rate = 0.02, max_features = 0.7, n_estimators = 700 , max_depth = 5).fit(X_train,y_train)\n",
    "    predict = model.predict_proba(X_test)[:,1]\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n",
    "\n",
    "def logistic_model(X_train, y_train, X_test, y_test=None):\n",
    "    model = LogisticRegression(penalty = 'l2').fit(X_train,y_train)\n",
    "    return model.predict_proba(X_test)[:,1]\n",
    "\n",
    "def lgb_feature(X_train, y_train, X_test, y_test=None):\n",
    "    lgb_train = lgb.Dataset(X_train, y_train,categorical_feature={'sex', 'merriage', 'income', 'qq_bound', 'degree', 'wechat_bound','account_grade','industry'})\n",
    "    lgb_test = lgb.Dataset(X_test,categorical_feature={'sex', 'merriage', 'income', 'qq_bound', 'degree', 'wechat_bound','account_grade','industry'})\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric':'auc',\n",
    "        'num_leaves': 25,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 5,\n",
    "        'min_data_in_leaf':5,\n",
    "        'max_bin':200,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "    gbm = lgb.train(params,lgb_train,num_boost_round=2000)\n",
    "    predict = gbm.predict(X_test)\n",
    "    minmin = min(predict)\n",
    "    maxmax = max(predict)\n",
    "    vfunc = np.vectorize(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "    return vfunc(predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d1827",
   "metadata": {},
   "source": [
    "## 验证v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "379adf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_df \n",
      "           id  title  career  zip_code  residence  syndicated  installment  \\\n",
      "0          0      9     0.0    221373          1           0            1   \n",
      "1          1      8    10.0    311681          0           0            0   \n",
      "2          2      8     7.0    271562          1           0            0   \n",
      "3          3      7     2.0    522083          0           0            1   \n",
      "4          4      8     3.0    101026          1           0            0   \n",
      "...      ...    ...     ...       ...        ...         ...          ...   \n",
      "53475  53475      2     2.0    603000          1           0            0   \n",
      "53476  53476      0    10.0    601702          1           0            0   \n",
      "53477  53477      2    10.0    602808          1           0            0   \n",
      "53478  53478      0    10.0    602102          2           0            0   \n",
      "53479  53479      0    10.0    602207          1           0            0   \n",
      "\n",
      "       level_A0  level_A1  level_A2  ...  level_D1  level_D2  level_D3  \\\n",
      "0             0         0         0  ...         0         0         0   \n",
      "1             0         0         0  ...         0         0         0   \n",
      "2             0         0         0  ...         0         0         0   \n",
      "3             0         0         0  ...         0         0         0   \n",
      "4             0         0         0  ...         0         0         0   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "53475         0         0         0  ...         0         0         0   \n",
      "53476         0         0         0  ...         0         0         0   \n",
      "53477         0         0         0  ...         0         0         0   \n",
      "53478         0         0         1  ...         0         0         0   \n",
      "53479         1         0         0  ...         0         0         0   \n",
      "\n",
      "       level_D4  level_D5  level_E1  level_E2  level_E3  level_E4  level_E5  \n",
      "0             0         0         0         0         0         0         0  \n",
      "1             0         0         0         0         0         0         0  \n",
      "2             0         0         0         0         0         0         0  \n",
      "3             0         0         0         0         0         0         0  \n",
      "4             0         0         0         0         0         0         0  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "53475         0         0         0         0         0         0         0  \n",
      "53476         0         0         0         0         0         0         0  \n",
      "53477         0         0         0         0         0         0         0  \n",
      "53478         0         0         0         0         0         0         0  \n",
      "53479         0         0         0         0         0         0         0  \n",
      "\n",
      "[53480 rows x 34 columns]\n",
      "valid sample data :\n",
      "  Index(['Unnamed: 0', 'loan', 'term', 'interest_rate', 'issue_time',\n",
      "       'record_time', 'history_time', 'total_accounts', 'balance_accounts',\n",
      "       'balance_limit', 'balance', 'label', '0', '1', '2', '3', '4', '5', '6',\n",
      "       '7', 'level_A0', 'level_A1', 'level_A2', 'level_A3', 'level_A4',\n",
      "       'level_A5', 'level_B0', 'level_B1', 'level_B2', 'level_B3', 'level_B4',\n",
      "       'level_B5', 'level_C1', 'level_C2', 'level_C3', 'level_C4', 'level_C5',\n",
      "       'level_D1', 'level_D2', 'level_D3', 'level_D4', 'level_D5', 'level_E1',\n",
      "       'level_E2', 'level_E3', 'level_E4', 'level_E5'],\n",
      "      dtype='object')\n",
      "logistic_model valid auc 0.5355081051413549\n",
      "gbdt_model valid auc 0.6626217868716636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dummy_fea_str = \"id,title,career,zip_code,residence,syndicated,installment,level\"\n",
    "dummy_fea = dummy_fea_str.split(',')\n",
    "\n",
    "sample_data = pd.read_csv('train.dat', engine = 'python');\n",
    "sample_data = sample_data.fillna(0)\n",
    "dummy_df = pd.get_dummies(sample_data.loc[:,dummy_fea])\n",
    "print('dummy_df \\n',dummy_df)\n",
    "\n",
    "sample_data_concat = pd.concat([sample_data, dummy_df], axis=1)\n",
    "sample_data_concat =sample_data_concat.fillna(0)\n",
    "vaild_sample_data = sample_data_concat.drop(dummy_fea, axis=1)\n",
    "print('valid sample data :\\n ',vaild_sample_data.columns)\n",
    "\n",
    "sample_data_target = vaild_sample_data['label'].values\n",
    "sample_data_x = vaild_sample_data.drop(['label'],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_data_x, sample_data_target, test_size=0.2, random_state=10, shuffle=True)\n",
    "\n",
    "# logistic model\n",
    "predict_result = logistic_model(X_train, y_train, X_test, None)\n",
    "print('logistic_model valid auc :', roc_auc_score(y_test, predict_result))\n",
    "\n",
    "# gbdt model\n",
    "predict_result = gbdt_model(X_train, y_train, X_test, None)\n",
    "print('gbdt_model valid auc : ', roc_auc_score(y_test, predict_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9358be",
   "metadata": {},
   "source": [
    "## 验证v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88571cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb sample data\n",
      "        Unnamed: 0     id  title  career  zip_code  residence   loan  term  \\\n",
      "0               0      0      9       0       271          1   7200    36   \n",
      "1               1      1      8      10       508          0  21300    36   \n",
      "2               2      2      8       7       424          1  10400    60   \n",
      "3               3      3      7       2       766          0  33050    36   \n",
      "4               4      4      8       3        25          1   5200    36   \n",
      "...           ...    ...    ...     ...       ...        ...    ...   ...   \n",
      "53475       53475  53475      2       2      1057          1   9000    12   \n",
      "53476       53476  53476      0      10       916          1   8000    12   \n",
      "53477       53477  53477      2      10      1043          1  10000    12   \n",
      "53478       53478  53478      0      10       960          2   9000    12   \n",
      "53479       53479  53479      0      10       976          1  10000    12   \n",
      "\n",
      "       interest_rate  issue_time  ...  level  label      0      1  \\\n",
      "0              10.95  1238631967  ...      4      0  163.0   48.0   \n",
      "1              12.95  1128212052  ...      6      1    0.0    0.0   \n",
      "2              21.05  1249171509  ...     10      0  180.0   48.0   \n",
      "3              16.40  1172882234  ...      9      0    0.0    0.0   \n",
      "4              14.35  1172882384  ...      8      1  169.0   93.0   \n",
      "...              ...         ...  ...    ...    ...    ...    ...   \n",
      "53475          23.55  1172880000  ...      4      0    0.0    0.0   \n",
      "53476          30.70  1160092800  ...      8      0    0.0    0.0   \n",
      "53477           9.40  1180310400  ...      8      0  180.0  251.0   \n",
      "53478          24.40  1176768000  ...      2      0    0.0    0.0   \n",
      "53479          17.60  1176163200  ...      0      0    0.0    0.0   \n",
      "\n",
      "                   2             3             4         5         6         7  \n",
      "0       71787.000000  12079.500000  59707.500000  437.7256   73.6555  364.0701  \n",
      "1           0.000000      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "2       22406.100000  15883.720000   6522.380000  123.7906   87.7554   36.0352  \n",
      "3           0.000000      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "4       51163.000000  30823.100000  20339.900000  300.9588  181.3124  119.6465  \n",
      "...              ...           ...           ...       ...       ...       ...  \n",
      "53475       0.000000      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "53476       0.000000      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "53477  113461.244335  69300.836223  44160.408112  626.8577  382.8775  243.9802  \n",
      "53478       0.000000      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "53479       0.000000      0.000000      0.000000    0.0000    0.0000    0.0000  \n",
      "\n",
      "[53480 rows x 28 columns]\n",
      "xgb dummy_df\n",
      "            id  title  career  zip_code  residence  syndicated  installment  \\\n",
      "0          0      9     0.0    221373          1           0            1   \n",
      "1          1      8    10.0    311681          0           0            0   \n",
      "2          2      8     7.0    271562          1           0            0   \n",
      "3          3      7     2.0    522083          0           0            1   \n",
      "4          4      8     3.0    101026          1           0            0   \n",
      "...      ...    ...     ...       ...        ...         ...          ...   \n",
      "53475  53475      2     2.0    603000          1           0            0   \n",
      "53476  53476      0    10.0    601702          1           0            0   \n",
      "53477  53477      2    10.0    602808          1           0            0   \n",
      "53478  53478      0    10.0    602102          2           0            0   \n",
      "53479  53479      0    10.0    602207          1           0            0   \n",
      "\n",
      "       level_A0  level_A1  level_A2  ...  level_D1  level_D2  level_D3  \\\n",
      "0             0         0         0  ...         0         0         0   \n",
      "1             0         0         0  ...         0         0         0   \n",
      "2             0         0         0  ...         0         0         0   \n",
      "3             0         0         0  ...         0         0         0   \n",
      "4             0         0         0  ...         0         0         0   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "53475         0         0         0  ...         0         0         0   \n",
      "53476         0         0         0  ...         0         0         0   \n",
      "53477         0         0         0  ...         0         0         0   \n",
      "53478         0         0         1  ...         0         0         0   \n",
      "53479         1         0         0  ...         0         0         0   \n",
      "\n",
      "       level_D4  level_D5  level_E1  level_E2  level_E3  level_E4  level_E5  \n",
      "0             0         0         0         0         0         0         0  \n",
      "1             0         0         0         0         0         0         0  \n",
      "2             0         0         0         0         0         0         0  \n",
      "3             0         0         0         0         0         0         0  \n",
      "4             0         0         0         0         0         0         0  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "53475         0         0         0         0         0         0         0  \n",
      "53476         0         0         0         0         0         0         0  \n",
      "53477         0         0         0         0         0         0         0  \n",
      "53478         0         0         0         0         0         0         0  \n",
      "53479         0         0         0         0         0         0         0  \n",
      "\n",
      "[53480 rows x 34 columns]\n",
      "xgb valid sample data Index(['Unnamed: 0', 'loan', 'term', 'interest_rate', 'issue_time',\n",
      "       'record_time', 'history_time', 'total_accounts', 'balance_accounts',\n",
      "       'balance_limit', 'balance', 'label', '0', '1', '2', '3', '4', '5', '6',\n",
      "       '7', 'level_A0', 'level_A1', 'level_A2', 'level_A3', 'level_A4',\n",
      "       'level_A5', 'level_B0', 'level_B1', 'level_B2', 'level_B3', 'level_B4',\n",
      "       'level_B5', 'level_C1', 'level_C2', 'level_C3', 'level_C4', 'level_C5',\n",
      "       'level_D1', 'level_D2', 'level_D3', 'level_D4', 'level_D5', 'level_E1',\n",
      "       'level_E2', 'level_E3', 'level_E4', 'level_E5'],\n",
      "      dtype='object')\n",
      "[20:50:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:51:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:52:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:53:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:54:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:55:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:56:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:57:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:58:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:59:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:00:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:01:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:02:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:04:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Do not support special JSON characters in feature name.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30392\\3973946526.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelsPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_xgb2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_xgb3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_lgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_gbdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mstack_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_diff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0mstacker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstack_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'fit_intercept'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mpredict_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\chenchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\heamy\\pipeline.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(self, k, stratify, shuffle, seed, full_test, add_diff)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m             \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerate_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerate_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\chenchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\heamy\\estimator.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(self, k, stratify, shuffle, seed, full_test)\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calculating %s\\'s fold #%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfull_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m                 \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreshape_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0mxt_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\chenchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\heamy\\estimator.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;31m# function-based definition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             result = self._estimator(X_train=X_train, y_train=y_train,\n\u001b[1;32m--> 121\u001b[1;33m                                      X_test=X_test, y_test=y_test, **self.parameters)\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30392\\83611539.py\u001b[0m in \u001b[0;36mlgb_feature\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;34m'verbose'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     }\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mgbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlgb_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mminmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\chenchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\chenchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[0;32m   3654\u001b[0m                 )\n\u001b[0;32m   3655\u001b[0m             \u001b[1;31m# construct booster object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3656\u001b[1;33m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3657\u001b[0m             \u001b[1;31m# copy the parameters from train_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3658\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\chenchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2599\u001b[0m                     \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2600\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2601\u001b[1;33m                     \u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2602\u001b[0m                 )\n\u001b[0;32m   2603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\chenchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   2225\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Wrong predictor type {type(predictor).__name__}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m         \u001b[1;31m# set feature names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_feature_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2229\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\chenchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mset_feature_name\u001b[1;34m(self, feature_name)\u001b[0m\n\u001b[0;32m   3048\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m                     \u001b[0m_c_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_feature_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m                 )\n\u001b[0;32m   3052\u001b[0m             )\n",
      "\u001b[1;32md:\\users\\chenchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \"\"\"\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Do not support special JSON characters in feature name."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dummy_fea_str = \"id,title,career,zip_code,residence,syndicated,installment,level\"\n",
    "dummy_fea = dummy_fea_str.split(',')\n",
    "\n",
    "sample_data_0 = pd.read_csv('train.dat', engine = 'python');\n",
    "sample_data = sample_data_0.fillna(0)\n",
    "\n",
    "#1. lgb feature\n",
    "#处理dummy变量\n",
    "for _fea in dummy_fea:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(sample_data[_fea].tolist())\n",
    "    tmp = le.transform(sample_data[_fea].tolist())\n",
    "    sample_data[_fea] = tmp\n",
    "print('lgb sample data\\n', sample_data)\n",
    "sample_data_target = sample_data['label'].values\n",
    "sample_data_x      = sample_data.drop(['label'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_data_x, sample_data_target, test_size=0.2, random_state=None, shuffle=True)\n",
    "lgb_dataset = Dataset(X_train=X_train, y_train=y_train, X_test = X_test, y_test= None, use_cache=False)\n",
    "\n",
    "\n",
    "##2. xgb feature\n",
    "sample_data = sample_data_0.fillna(0)\n",
    "dummy_df = pd.get_dummies(sample_data.loc[:,dummy_fea])\n",
    "print('xgb dummy_df\\n ',dummy_df)\n",
    "sample_data_concat = pd.concat([sample_data, dummy_df], axis=1)\n",
    "sample_data_concat = sample_data_concat.fillna(0)\n",
    "vaild_sample_data = sample_data_concat.drop(dummy_fea, axis=1)\n",
    "print('xgb valid sample data', vaild_sample_data.columns)\n",
    "\n",
    "sample_data_target = vaild_sample_data['label'].values\n",
    "sample_data_x = vaild_sample_data.drop(['label'],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_data_x, sample_data_target, test_size=0.2, random_state=None, shuffle=True)\n",
    "xgb_dataset = Dataset(X_train=X_train, y_train=y_train, X_test = X_test, y_test= None, use_cache=False)\n",
    "\n",
    "model_xgb  = Regressor(dataset=xgb_dataset, estimator=xgb_feature,name='xgb',use_cache=False)\n",
    "model_xgb2 = Regressor(dataset=xgb_dataset, estimator=xgb_feature2,name='xgb2',use_cache=False)\n",
    "model_xgb3 = Regressor(dataset=xgb_dataset, estimator=xgb_feature3,name='xgb3',use_cache=False)\n",
    "model_lgb = Regressor(dataset=lgb_dataset, estimator=lgb_feature,name='lgb',use_cache=False)\n",
    "model_gbdt = Regressor(dataset=xgb_dataset, estimator=gbdt_model,name='gbdt',use_cache=False)\n",
    "\n",
    "pipeline = ModelsPipeline(model_xgb, model_xgb2, model_xgb3, model_lgb, model_gbdt)\n",
    "stack_ds = pipeline.stack(k=5, seed=111, add_diff=False, full_test=True)\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LinearRegression, parameters={'fit_intercept': False})\n",
    "predict_result = stacker.predict()\n",
    "\n",
    "print('ModelsPipeline(model_xgb, model_xgb2, model_xgb3, model_gbdt) valid auc', roc_auc_score(y_test, predict_result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57a661b",
   "metadata": {},
   "source": [
    "## lgb feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.dat',engine = 'python');\n",
    "train_data = train_data.fillna(0)\n",
    "\n",
    "test_data = pd.read_csv('test.dat',engine = 'python');\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "train_test_data = pd.concat([train_data, test_data],axis=0,ignore_index = True)\n",
    "train_test_data = train_test_data.fillna(0)\n",
    "\n",
    "train_data = train_test_data.iloc[:train_data.shape[0],:]\n",
    "test_data = train_test_data.iloc[train_data.shape[0]:,:]\n",
    "\n",
    "#处理dummy变量\n",
    "for _fea in dummy_fea:\n",
    "    print(_fea)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data[_fea].tolist() + test_data[_fea].tolist())\n",
    "    tmp = le.transform(train_data[_fea].tolist() + test_data[_fea].tolist())\n",
    "    train_data[_fea] = tmp[:train_data.shape[0]]\n",
    "    test_data[_fea]  = tmp[train_data.shape[0]:]\n",
    "    \n",
    "train_x = train_data.drop(['label'],axis=1)\n",
    "test_x = test_data.drop(['label'],axis=1)\n",
    "lgb_dataset = Dataset(train_x, train_data['label'], test_x, use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fe88f",
   "metadata": {},
   "source": [
    "## xgb feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.dat',engine = 'python');\n",
    "train_data = train_data.fillna(0)\n",
    "\n",
    "test_data = pd.read_csv('test.dat',engine = 'python');\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "train_test_data = pd.concat([train_data, test_data], axis=0, ignore_index = True)\n",
    "train_test_data = train_test_data.fillna(0)\n",
    "\n",
    "dummy_df = pd.get_dummies(train_test_data.loc[:,dummy_fea])\n",
    "train_test_data = pd.concat([train_test_data, dummy_df],axis=1)\n",
    "train_test_data = train_test_data.drop(dummy_fea, axis=1)\n",
    "\n",
    "train_train = train_test_data.iloc[:train_data.shape[0],:]\n",
    "test_test = train_test_data.iloc[train_data.shape[0]:,:]\n",
    "\n",
    "train_train_x = train_train.drop(['target'],axis=1)\n",
    "test_test_x = test_test.drop(['target'],axis=1)\n",
    "\n",
    "xgb_dataset = Dataset(X_train=train_train_x, y_train=train_train['target'], X_test = test_test_x, y_test= None, use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6906bb",
   "metadata": {},
   "source": [
    "## stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = Regressor(dataset=xgb_dataset, estimator=xgb_feature,name='xgb',use_cache=False)\n",
    "model_xgb2 = Regressor(dataset=xgb_dataset, estimator=xgb_feature2,name='xgb2',use_cache=False)\n",
    "model_xgb3 = Regressor(dataset=xgb_dataset, estimator=xgb_feature3,name='xgb3',use_cache=False)\n",
    "model_lgb = Regressor(dataset=lgb_dataset, estimator=lgb_feature,name='lgb',use_cache=False)\n",
    "model_gbdt = Regressor(dataset=xgb_dataset, estimator=gbdt_model,name='gbdt',use_cache=False)\n",
    "pipeline = ModelsPipeline(model_xgb, model_xgb2, model_xgb3, model_gbdt)\n",
    "stack_ds = pipeline.stack(k=5, seed=111, add_diff=False, full_test=True)\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LinearRegression,parameters={'fit_intercept': False})\n",
    "predict_result = stacker.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.read_csv('testaa.csv')\n",
    "ans['PROB'] = predict_result\n",
    "minmin = min(ans['PROB']),\n",
    "maxmax = max(ans['PROB'])\n",
    "ans['PROB'] = ans['PROB'].map(lambda x:(x-minmin)/(maxmax-minmin))\n",
    "ans['PROB'] = ans['PROB'].map(lambda x:'%.4f' % x)\n",
    "ans.to_csv('./ans_stacking.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
